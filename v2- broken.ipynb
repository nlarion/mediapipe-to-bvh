{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d923def-efbe-4ed0-8435-fcc7758071a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 15:55:32.072266: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740441332.089152   49931 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740441332.094590   49931 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-24 15:55:32.112318: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from math import sqrt, atan2, pi\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "857c257e-15a7-418d-a38f-4d101251b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_euler_angles(landmarks):\n",
    "    \"\"\"Calculate the Euler angles ( yaw, pitch, roll ) for each pose.\"\"\"\n",
    "    \n",
    "    # Get coordinates of key landmarks\n",
    "    left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "    right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "    left_elbow = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]\n",
    "    right_elbow = landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value]\n",
    "    left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "    right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]\n",
    "\n",
    "    # Calculate vectors for rotation\n",
    "    shoulder_to_elbow_left = (left_elbow.x - left_shoulder.x, \n",
    "                              left_elbow.y - left_shoulder.y,\n",
    "                              left_elbow.z - left_shoulder.z)\n",
    "    \n",
    "    shoulder_to_hip_right = (right_hip.x - right_shoulder.x,\n",
    "                             right_hip.y - right_shoulder.y,\n",
    "                             right_hip.z - right_shoulder.z)\n",
    "\n",
    "    # Calculate Euler angles\n",
    "    yaw = atan2(shoulder_to_elbow_left[1], shoulder_to_elbow_left[0])\n",
    "    pitch = atan2(-shoulder_to_hip_right[2], sqrt(shoulder_to_hip_right[0]**2 + shoulder_to_hip_right[1]**2))\n",
    "    roll = 0.0\n",
    "\n",
    "    return yaw, pitch, roll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df5ba296-cfcb-4bca-847b-021dffa1c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_bvh_file(euler_angles):\n",
    "    \"\"\"Write the Euler angles to a BVH file.\"\"\"\n",
    "    \n",
    "    # Define joint hierarchy (simplified for demonstration)\n",
    "    joints = [\n",
    "        \"Root\",\n",
    "        \"LeftArm\",\n",
    "        \"RightArm\",\n",
    "        \"LeftLeg\",\n",
    "        \"RightLeg\"\n",
    "    ]\n",
    "    \n",
    "    with open(\"output.bvh\", \"w\") as f:\n",
    "        f.write(\"VERSION 1.3\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # Write translation (assuming root is at origin)\n",
    "        f.write(\"ROOT Root\\n\")\n",
    "        f.write(f\"   CHAIN {joints[0]}\\n\")\n",
    "        f.write(\"   TO WorldTransform{\\n\")\n",
    "        f.write(\"      t 0.0 0.0 0.0\\n\")\n",
    "        \n",
    "        # Write Euler angles\n",
    "        for i, joint in enumerate(joints):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            \n",
    "            f.write(f\"\\nJOINT {joint}\\n\")\n",
    "            f.write(f\"   PARENT {joints[i-1]}\\n\")\n",
    "            f.write(\"   CHAIN \" + joints[i] + \"\\n\")\n",
    "            f.write(\"   ROTZ YAW\\n\")\n",
    "            f.write(f\"      r 0.0 {euler_angles[0]} 0.0\\n\")  # yaw\n",
    "            f.write(\"   ROTX PITCH\\n\")\n",
    "            f.write(f\"      r 0.0 {euler_angles[1]} 0.0\\n\")  # pitch\n",
    "            f.write(\"   ROTY ROLL\\n\")\n",
    "            f.write(f\"      r 0.0 {euler_angles[2]} 0.0\\n\")  # roll\n",
    "            \n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e6182a-fd70-4241-bd76-a9174a227da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to process pose data and write BVH file.\"\"\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)  # Use webcam\n",
    "    \n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            \n",
    "            if not success:\n",
    "                break\n",
    "            \n",
    "            image.flags.writeable = False\n",
    "            results = pose.process(image)\n",
    "            image.flags.writeable = True\n",
    "            \n",
    "            if results.pose_landmarks is not None:\n",
    "                euler_angles = calculate_euler_angles(results.pose_landmarks.landmark)\n",
    "                \n",
    "                # Convert radians to degrees (optional, depending on BVH requirements)\n",
    "                euler_degrees = [angle * 180.0 / pi for angle in euler_angles]\n",
    "                \n",
    "                write_bvh_file(euler_degrees)\n",
    "                \n",
    "            cv2.imshow('MediaPipe Pose', image)\n",
    "            \n",
    "            if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33db5b90-d122-4109-8be7-96580b83add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740441226.241369   49536 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1740441226.243669   49786 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1740441226.315488   49763 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740441226.350631   49771 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740441228.646092   49765 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp_pose\u001b[38;5;241m.\u001b[39mPose(min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, min_tracking_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pose:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m----> 8\u001b[0m         success, image \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1efdf3c-9ad2-47ec-912f-3086377cc6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
