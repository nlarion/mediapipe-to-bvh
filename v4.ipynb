{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cee9918-2d32-442c-a6a8-3453aa3ee454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 16:50:14.033580: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740617414.050406   26509 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740617414.055815   26509 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-26 16:50:14.072904: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import argparse\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "\n",
    "# BVH creation utilities\n",
    "class Joint:\n",
    "    def __init__(self, name, parent=None):\n",
    "        self.name = name\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.offset = np.zeros(3)\n",
    "        self.channels = []\n",
    "        self.motion = []\n",
    "        \n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "        \n",
    "class BVHSkeleton:\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "        self.joints = {}\n",
    "        self.frames = 0\n",
    "        self.frame_time = 1.0/30.0  # Default to 30fps\n",
    "        \n",
    "    def create_hierarchy(self):\n",
    "        \"\"\"Create a standard BVH hierarchy that matches MediaPipe landmarks\"\"\"\n",
    "        \n",
    "        # Create the root joint (Hips)\n",
    "        self.root = Joint(\"Hips\")\n",
    "        self.joints[\"Hips\"] = self.root\n",
    "        \n",
    "        # Create spine chain\n",
    "        spine = Joint(\"Spine\", self.root)\n",
    "        self.root.add_child(spine)\n",
    "        self.joints[\"Spine\"] = spine\n",
    "        \n",
    "        chest = Joint(\"Chest\", spine)\n",
    "        spine.add_child(chest)\n",
    "        self.joints[\"Chest\"] = chest\n",
    "        \n",
    "        neck = Joint(\"Neck\", chest)\n",
    "        chest.add_child(neck)\n",
    "        self.joints[\"Neck\"] = neck\n",
    "        \n",
    "        head = Joint(\"Head\", neck)\n",
    "        neck.add_child(head)\n",
    "        self.joints[\"Head\"] = head\n",
    "        \n",
    "        # Create left arm\n",
    "        l_collar = Joint(\"LeftCollar\", chest)\n",
    "        chest.add_child(l_collar)\n",
    "        self.joints[\"LeftCollar\"] = l_collar\n",
    "        \n",
    "        l_shoulder = Joint(\"LeftShoulder\", l_collar)\n",
    "        l_collar.add_child(l_shoulder)\n",
    "        self.joints[\"LeftShoulder\"] = l_shoulder\n",
    "        \n",
    "        l_elbow = Joint(\"LeftElbow\", l_shoulder)\n",
    "        l_shoulder.add_child(l_elbow)\n",
    "        self.joints[\"LeftElbow\"] = l_elbow\n",
    "        \n",
    "        l_wrist = Joint(\"LeftWrist\", l_elbow)\n",
    "        l_elbow.add_child(l_wrist)\n",
    "        self.joints[\"LeftWrist\"] = l_wrist\n",
    "        \n",
    "        # Create left hand (simplified)\n",
    "        l_hand = Joint(\"LeftHand\", l_wrist)\n",
    "        l_wrist.add_child(l_hand)\n",
    "        self.joints[\"LeftHand\"] = l_hand\n",
    "        \n",
    "        # Create right arm\n",
    "        r_collar = Joint(\"RightCollar\", chest)\n",
    "        chest.add_child(r_collar)\n",
    "        self.joints[\"RightCollar\"] = r_collar\n",
    "        \n",
    "        r_shoulder = Joint(\"RightShoulder\", r_collar)\n",
    "        r_collar.add_child(r_shoulder)\n",
    "        self.joints[\"RightShoulder\"] = r_shoulder\n",
    "        \n",
    "        r_elbow = Joint(\"RightElbow\", r_shoulder)\n",
    "        r_shoulder.add_child(r_elbow)\n",
    "        self.joints[\"RightElbow\"] = r_elbow\n",
    "        \n",
    "        r_wrist = Joint(\"RightWrist\", r_elbow)\n",
    "        r_elbow.add_child(r_wrist)\n",
    "        self.joints[\"RightWrist\"] = r_wrist\n",
    "        \n",
    "        # Create right hand (simplified)\n",
    "        r_hand = Joint(\"RightHand\", r_wrist)\n",
    "        r_wrist.add_child(r_hand)\n",
    "        self.joints[\"RightHand\"] = r_hand\n",
    "        \n",
    "        # Create left leg\n",
    "        l_hip = Joint(\"LeftHip\", self.root)\n",
    "        self.root.add_child(l_hip)\n",
    "        self.joints[\"LeftHip\"] = l_hip\n",
    "        \n",
    "        l_knee = Joint(\"LeftKnee\", l_hip)\n",
    "        l_hip.add_child(l_knee)\n",
    "        self.joints[\"LeftKnee\"] = l_knee\n",
    "        \n",
    "        l_ankle = Joint(\"LeftAnkle\", l_knee)\n",
    "        l_knee.add_child(l_ankle)\n",
    "        self.joints[\"LeftAnkle\"] = l_ankle\n",
    "        \n",
    "        l_foot = Joint(\"LeftFoot\", l_ankle)\n",
    "        l_ankle.add_child(l_foot)\n",
    "        self.joints[\"LeftFoot\"] = l_foot\n",
    "        \n",
    "        # Create right leg\n",
    "        r_hip = Joint(\"RightHip\", self.root)\n",
    "        self.root.add_child(r_hip)\n",
    "        self.joints[\"RightHip\"] = r_hip\n",
    "        \n",
    "        r_knee = Joint(\"RightKnee\", r_hip)\n",
    "        r_hip.add_child(r_knee)\n",
    "        self.joints[\"RightKnee\"] = r_knee\n",
    "        \n",
    "        r_ankle = Joint(\"RightAnkle\", r_knee)\n",
    "        r_knee.add_child(r_ankle)\n",
    "        self.joints[\"RightAnkle\"] = r_ankle\n",
    "        \n",
    "        r_foot = Joint(\"RightFoot\", r_ankle)\n",
    "        r_ankle.add_child(r_foot)\n",
    "        self.joints[\"RightFoot\"] = r_foot\n",
    "        \n",
    "        # Setup channels for each joint\n",
    "        self.setup_channels()\n",
    "    \n",
    "    def setup_channels(self):\n",
    "        \"\"\"Set up the channels for each joint in the hierarchy\"\"\"\n",
    "        # Root has 6 channels: position and rotation\n",
    "        self.root.channels = [\"Xposition\", \"Yposition\", \"Zposition\", \"Zrotation\", \"Xrotation\", \"Yrotation\"]\n",
    "        \n",
    "        # All other joints have 3 channels (rotation only)\n",
    "        for name, joint in self.joints.items():\n",
    "            if joint != self.root:\n",
    "                joint.channels = [\"Zrotation\", \"Xrotation\", \"Yrotation\"]\n",
    "    \n",
    "    def update_joint_offsets(self, landmarks):\n",
    "        \"\"\"Calculate the initial offsets between joints based on the first frame of landmarks\"\"\"\n",
    "        \n",
    "        # Create a mapping from joint names to MediaPipe landmark indices\n",
    "        # Based on MediaPipe's pose landmark model: https://google.github.io/mediapipe/solutions/pose.html\n",
    "        mapping = {\n",
    "            \"Hips\": 23,          # Left hip (will be centered)\n",
    "            \"Spine\": 24,         # Right hip (will average with left hip)\n",
    "            \"Chest\": 11,         # Left shoulder (midpoint with right)\n",
    "            \"Neck\": 12,          # Right shoulder (midpoint for neck base)\n",
    "            \"Head\": 0,           # Nose\n",
    "            \"LeftCollar\": 11,    # Left shoulder\n",
    "            \"LeftShoulder\": 11,  # Left shoulder\n",
    "            \"LeftElbow\": 13,     # Left elbow\n",
    "            \"LeftWrist\": 15,     # Left wrist\n",
    "            \"LeftHand\": 19,      # Left hand (index finger MCP)\n",
    "            \"RightCollar\": 12,   # Right shoulder\n",
    "            \"RightShoulder\": 12, # Right shoulder\n",
    "            \"RightElbow\": 14,    # Right elbow\n",
    "            \"RightWrist\": 16,    # Right wrist\n",
    "            \"RightHand\": 20,     # Right hand (index finger MCP)\n",
    "            \"LeftHip\": 23,       # Left hip\n",
    "            \"LeftKnee\": 25,      # Left knee\n",
    "            \"LeftAnkle\": 27,     # Left ankle\n",
    "            \"LeftFoot\": 31,      # Left foot index\n",
    "            \"RightHip\": 24,      # Right hip\n",
    "            \"RightKnee\": 26,     # Right knee\n",
    "            \"RightAnkle\": 28,    # Right ankle\n",
    "            \"RightFoot\": 32,     # Right foot index\n",
    "        }\n",
    "        \n",
    "        # Scale to make the skeleton more appropriate size for BVH\n",
    "        scale_factor = 100\n",
    "        \n",
    "        # First calculate the root position (centered between hips)\n",
    "        left_hip = np.array([landmarks[23].x, landmarks[23].y, landmarks[23].z])\n",
    "        right_hip = np.array([landmarks[24].x, landmarks[24].y, landmarks[24].z])\n",
    "        hip_center = (left_hip + right_hip) / 2\n",
    "        \n",
    "        # Store original coordinates to calculate offsets\n",
    "        coords = {}\n",
    "        for name, idx in mapping.items():\n",
    "            if idx is not None:\n",
    "                coords[name] = np.array([landmarks[idx].x, landmarks[idx].y, landmarks[idx].z])\n",
    "            \n",
    "        # Calculate special midpoints\n",
    "        coords[\"Spine\"] = hip_center\n",
    "        left_shoulder = coords[\"LeftShoulder\"]  \n",
    "        right_shoulder = coords[\"RightShoulder\"]\n",
    "        coords[\"Chest\"] = (left_shoulder + right_shoulder) / 2\n",
    "        coords[\"Neck\"] = (left_shoulder + right_shoulder) / 2\n",
    "        \n",
    "        # Set the hip center at the origin\n",
    "        for name, pos in coords.items():\n",
    "            coords[name] = (pos - hip_center) * scale_factor\n",
    "            # In BVH, Y is up, but in MediaPipe Y is down - flip Y\n",
    "            coords[name][1] = -coords[name][1]\n",
    "                \n",
    "        # Calculate offsets based on joint hierarchy\n",
    "        for name, joint in self.joints.items():\n",
    "            if joint.parent is None:\n",
    "                # Root joint\n",
    "                joint.offset = np.zeros(3)\n",
    "            else:\n",
    "                # Child joints\n",
    "                parent_name = joint.parent.name\n",
    "                # For specific joints, use mediapipe's landmarks directly\n",
    "                joint.offset = coords[name] - coords[parent_name]\n",
    "    \n",
    "    def quaternion_to_euler(self, q):\n",
    "        \"\"\"Convert quaternion to Euler angles (in degrees)\"\"\"\n",
    "        # Extract quaternion components\n",
    "        w, x, y, z = q\n",
    "        \n",
    "        # Roll (x-axis rotation)\n",
    "        sinr_cosp = 2 * (w * x + y * z)\n",
    "        cosr_cosp = 1 - 2 * (x * x + y * y)\n",
    "        roll = math.atan2(sinr_cosp, cosr_cosp)\n",
    "        \n",
    "        # Pitch (y-axis rotation)\n",
    "        sinp = 2 * (w * y - z * x)\n",
    "        if abs(sinp) >= 1:\n",
    "            pitch = math.copysign(math.pi / 2, sinp)  # Use 90 degrees if out of range\n",
    "        else:\n",
    "            pitch = math.asin(sinp)\n",
    "            \n",
    "        # Yaw (z-axis rotation)\n",
    "        siny_cosp = 2 * (w * z + x * y)\n",
    "        cosy_cosp = 1 - 2 * (y * y + z * z)\n",
    "        yaw = math.atan2(siny_cosp, cosy_cosp)\n",
    "        \n",
    "        # Convert to degrees\n",
    "        roll_deg = math.degrees(roll)\n",
    "        pitch_deg = math.degrees(pitch)\n",
    "        yaw_deg = math.degrees(yaw)\n",
    "        \n",
    "        return [yaw_deg, roll_deg, pitch_deg]  # ZXY order\n",
    "    \n",
    "    def get_bone_orientation(self, parent_pos, child_pos):\n",
    "        \"\"\"Calculate orientation from parent joint to child joint\"\"\"\n",
    "        # Vector from parent to child\n",
    "        direction = child_pos - parent_pos\n",
    "        length = np.linalg.norm(direction)\n",
    "        \n",
    "        if length < 1e-6:  # Avoid division by zero\n",
    "            return np.array([1, 0, 0, 0])  # Identity quaternion\n",
    "        \n",
    "        direction = direction / length\n",
    "        \n",
    "        # Original bone is assumed to point in the Y-axis in the rest pose\n",
    "        original = np.array([0, 1, 0])\n",
    "        \n",
    "        # Quaternion to rotate from original to direction\n",
    "        # First find rotation axis by cross product\n",
    "        axis = np.cross(original, direction)\n",
    "        axis_length = np.linalg.norm(axis)\n",
    "        \n",
    "        if axis_length < 1e-6:\n",
    "            # If vectors are parallel (or anti-parallel)\n",
    "            dot = np.dot(original, direction)\n",
    "            if dot > 0.999:\n",
    "                return np.array([1, 0, 0, 0])  # Identity quaternion\n",
    "            else:\n",
    "                # 180 degree rotation around X-axis\n",
    "                return np.array([0, 1, 0, 0])\n",
    "        \n",
    "        # Normalize axis\n",
    "        axis = axis / axis_length\n",
    "        \n",
    "        # Calculate rotation angle\n",
    "        angle = math.acos(np.clip(np.dot(original, direction), -1.0, 1.0))\n",
    "        \n",
    "        # Create quaternion [w, x, y, z]\n",
    "        s = math.sin(angle / 2)\n",
    "        quat = np.array([\n",
    "            math.cos(angle / 2),\n",
    "            axis[0] * s,\n",
    "            axis[1] * s,\n",
    "            axis[2] * s\n",
    "        ])\n",
    "        \n",
    "        return quat\n",
    "    \n",
    "    def process_frame(self, landmarks):\n",
    "        \"\"\"Process a frame of MediaPipe landmarks into joint rotations and positions\"\"\"\n",
    "        frame_data = []\n",
    "        \n",
    "        # Define coordinates for each joint\n",
    "        coords = {}\n",
    "        \n",
    "        # Get hip center (root position)\n",
    "        left_hip = np.array([landmarks[23].x, landmarks[23].y, landmarks[23].z])\n",
    "        right_hip = np.array([landmarks[24].x, landmarks[24].y, landmarks[24].z])\n",
    "        hip_center = (left_hip + right_hip) / 2\n",
    "        \n",
    "        # Root position\n",
    "        root_pos = np.array([\n",
    "            hip_center[0] * 100, \n",
    "            -hip_center[1] * 100,  # Y is inverted in MediaPipe vs BVH\n",
    "            hip_center[2] * 100\n",
    "        ])\n",
    "        \n",
    "        # Add root position to frame data\n",
    "        frame_data.extend(root_pos)\n",
    "        \n",
    "        # Define point locations for all joints\n",
    "        # These are raw coordinates we'll use to calculate orientations\n",
    "        points = {\n",
    "            # Spine and head\n",
    "            \"Hips\": hip_center,\n",
    "            \"Spine\": (left_hip + right_hip) / 2,\n",
    "            \"LeftShoulder\": np.array([landmarks[11].x, landmarks[11].y, landmarks[11].z]),\n",
    "            \"RightShoulder\": np.array([landmarks[12].x, landmarks[12].y, landmarks[12].z]),\n",
    "            \"Chest\": (np.array([landmarks[11].x, landmarks[11].y, landmarks[11].z]) + \n",
    "                      np.array([landmarks[12].x, landmarks[12].y, landmarks[12].z])) / 2,\n",
    "            \"Neck\": (np.array([landmarks[11].x, landmarks[11].y, landmarks[11].z]) + \n",
    "                     np.array([landmarks[12].x, landmarks[12].y, landmarks[12].z])) / 2,\n",
    "            \"Head\": np.array([landmarks[0].x, landmarks[0].y, landmarks[0].z]),\n",
    "            \n",
    "            # Left arm\n",
    "            \"LeftCollar\": np.array([landmarks[11].x, landmarks[11].y, landmarks[11].z]),\n",
    "            \"LeftElbow\": np.array([landmarks[13].x, landmarks[13].y, landmarks[13].z]),\n",
    "            \"LeftWrist\": np.array([landmarks[15].x, landmarks[15].y, landmarks[15].z]),\n",
    "            \"LeftHand\": np.array([landmarks[19].x, landmarks[19].y, landmarks[19].z]),\n",
    "            \n",
    "            # Right arm\n",
    "            \"RightCollar\": np.array([landmarks[12].x, landmarks[12].y, landmarks[12].z]),\n",
    "            \"RightElbow\": np.array([landmarks[14].x, landmarks[14].y, landmarks[14].z]),\n",
    "            \"RightWrist\": np.array([landmarks[16].x, landmarks[16].y, landmarks[16].z]),\n",
    "            \"RightHand\": np.array([landmarks[20].x, landmarks[20].y, landmarks[20].z]),\n",
    "            \n",
    "            # Left leg\n",
    "            \"LeftHip\": np.array([landmarks[23].x, landmarks[23].y, landmarks[23].z]),\n",
    "            \"LeftKnee\": np.array([landmarks[25].x, landmarks[25].y, landmarks[25].z]),\n",
    "            \"LeftAnkle\": np.array([landmarks[27].x, landmarks[27].y, landmarks[27].z]),\n",
    "            \"LeftFoot\": np.array([landmarks[31].x, landmarks[31].y, landmarks[31].z]),\n",
    "            \n",
    "            # Right leg\n",
    "            \"RightHip\": np.array([landmarks[24].x, landmarks[24].y, landmarks[24].z]),\n",
    "            \"RightKnee\": np.array([landmarks[26].x, landmarks[26].y, landmarks[26].z]),\n",
    "            \"RightAnkle\": np.array([landmarks[28].x, landmarks[28].y, landmarks[28].z]),\n",
    "            \"RightFoot\": np.array([landmarks[32].x, landmarks[32].y, landmarks[32].z]),\n",
    "        }\n",
    "        \n",
    "        # Define the hierarchy and connectivity for rotation calculations\n",
    "        hierarchy = {\n",
    "            \"Hips\": (\"Hips\", \"Spine\"),\n",
    "            \"Spine\": (\"Spine\", \"Chest\"),\n",
    "            \"Chest\": (\"Chest\", \"Neck\"),\n",
    "            \"Neck\": (\"Neck\", \"Head\"),\n",
    "            \"Head\": (\"Head\", None),\n",
    "            \n",
    "            \"LeftCollar\": (\"Chest\", \"LeftCollar\"),\n",
    "            \"LeftShoulder\": (\"LeftCollar\", \"LeftElbow\"),\n",
    "            \"LeftElbow\": (\"LeftElbow\", \"LeftWrist\"),\n",
    "            \"LeftWrist\": (\"LeftWrist\", \"LeftHand\"),\n",
    "            \"LeftHand\": (\"LeftHand\", None),\n",
    "            \n",
    "            \"RightCollar\": (\"Chest\", \"RightCollar\"),\n",
    "            \"RightShoulder\": (\"RightCollar\", \"RightElbow\"),\n",
    "            \"RightElbow\": (\"RightElbow\", \"RightWrist\"),\n",
    "            \"RightWrist\": (\"RightWrist\", \"RightHand\"),\n",
    "            \"RightHand\": (\"RightHand\", None),\n",
    "            \n",
    "            \"LeftHip\": (\"Hips\", \"LeftKnee\"),\n",
    "            \"LeftKnee\": (\"LeftKnee\", \"LeftAnkle\"),\n",
    "            \"LeftAnkle\": (\"LeftAnkle\", \"LeftFoot\"),\n",
    "            \"LeftFoot\": (\"LeftFoot\", None),\n",
    "            \n",
    "            \"RightHip\": (\"Hips\", \"RightKnee\"),\n",
    "            \"RightKnee\": (\"RightKnee\", \"RightAnkle\"),\n",
    "            \"RightAnkle\": (\"RightAnkle\", \"RightFoot\"),\n",
    "            \"RightFoot\": (\"RightFoot\", None),\n",
    "        }\n",
    "        \n",
    "        # Root rotation (global)\n",
    "        # Calculate the orientation using shoulders and hips\n",
    "        left_shoulder = points[\"LeftShoulder\"]\n",
    "        right_shoulder = points[\"RightShoulder\"] \n",
    "        left_hip = points[\"LeftHip\"]\n",
    "        right_hip = points[\"RightHip\"]\n",
    "        \n",
    "        # Calculate forward direction (perpendicular to the line between shoulders and hips)\n",
    "        shoulder_center = (left_shoulder + right_shoulder) / 2\n",
    "        hip_center = (left_hip + right_hip) / 2\n",
    "        up_direction = shoulder_center - hip_center\n",
    "        up_direction = up_direction / np.linalg.norm(up_direction)\n",
    "        \n",
    "        right_direction = right_shoulder - left_shoulder\n",
    "        right_direction = right_direction / np.linalg.norm(right_direction)\n",
    "        \n",
    "        forward_direction = np.cross(right_direction, up_direction)\n",
    "        forward_direction = forward_direction / np.linalg.norm(forward_direction)\n",
    "        \n",
    "        # Recalculate right to ensure orthogonal basis\n",
    "        right_direction = np.cross(up_direction, forward_direction)\n",
    "        \n",
    "        # Create rotation matrix for root\n",
    "        rot_matrix = np.vstack([right_direction, up_direction, forward_direction]).T\n",
    "        \n",
    "        # Extract Euler angles\n",
    "        # Simple approach: assumes the rotation matrix is orthogonal\n",
    "        yaw = math.atan2(rot_matrix[2, 0], rot_matrix[0, 0])\n",
    "        pitch = math.atan2(-rot_matrix[1, 2], rot_matrix[1, 1])\n",
    "        roll = math.atan2(-rot_matrix[2, 1], rot_matrix[2, 2])\n",
    "        \n",
    "        # Convert to degrees\n",
    "        root_rotation = [\n",
    "            math.degrees(yaw),     # Z\n",
    "            math.degrees(roll),    # X\n",
    "            math.degrees(pitch)    # Y\n",
    "        ]\n",
    "        \n",
    "        # Add root rotation\n",
    "        frame_data.extend(root_rotation)\n",
    "        \n",
    "        # Calculate orientations for all other joints\n",
    "        for name, joint in self.joints.items():\n",
    "            if joint == self.root:\n",
    "                # Already handled root above\n",
    "                continue\n",
    "            \n",
    "            # Get the points to calculate orientation from\n",
    "            source_name, target_name = hierarchy[name]\n",
    "            \n",
    "            if target_name is None:\n",
    "                # End sites just use parent rotation\n",
    "                source_name = joint.parent.name\n",
    "                target_name = name\n",
    "                # Default rotation for end sites\n",
    "                rotation = [0, 0, 0]\n",
    "            else:\n",
    "                # Get parent and child positions\n",
    "                parent_pos = points[source_name]\n",
    "                child_pos = points[target_name]\n",
    "                \n",
    "                # Get quaternion orientation\n",
    "                quat = self.get_bone_orientation(parent_pos, child_pos)\n",
    "                \n",
    "                # Convert to Euler angles\n",
    "                rotation = self.quaternion_to_euler(quat)\n",
    "            \n",
    "            # Add joint rotation to frame data\n",
    "            frame_data.extend(rotation)\n",
    "        \n",
    "        return frame_data\n",
    "    \n",
    "    def write_bvh(self, filename):\n",
    "        \"\"\"Write the skeleton and motion data to a BVH file\"\"\"\n",
    "        with open(filename, 'w') as f:\n",
    "            # Write header\n",
    "            f.write(\"HIERARCHY\\n\")\n",
    "            \n",
    "            # Write the skeleton hierarchy recursively\n",
    "            self._write_joint(f, self.root, 0)\n",
    "            \n",
    "            # Write motion data\n",
    "            f.write(\"MOTION\\n\")\n",
    "            f.write(f\"Frames: {self.frames}\\n\")\n",
    "            f.write(f\"Frame Time: {self.frame_time}\\n\")\n",
    "            \n",
    "            # Calculate total number of channels\n",
    "            total_channels = sum(len(joint.channels) for joint in self.joints.values())\n",
    "            \n",
    "            # Prepare motion data\n",
    "            motion_data = []\n",
    "            for frame in range(self.frames):\n",
    "                frame_values = []\n",
    "                \n",
    "                for name, joint in self.joints.items():\n",
    "                    if frame < len(joint.motion):\n",
    "                        # Add motion data for this joint\n",
    "                        frame_values.extend(joint.motion[frame])\n",
    "                    else:\n",
    "                        # Add zeros if missing data\n",
    "                        frame_values.extend([0.0] * len(joint.channels))\n",
    "                \n",
    "                # Make sure we have the right number of values\n",
    "                if len(frame_values) < total_channels:\n",
    "                    frame_values.extend([0.0] * (total_channels - len(frame_values)))\n",
    "                elif len(frame_values) > total_channels:\n",
    "                    frame_values = frame_values[:total_channels]\n",
    "                    \n",
    "                motion_data.append(frame_values)\n",
    "            \n",
    "            # Write frame data\n",
    "            for frame_values in motion_data:\n",
    "                f.write(\" \".join(map(lambda x: f\"{x:.6f}\", frame_values)) + \"\\n\")\n",
    "    \n",
    "    def _write_joint(self, f, joint, indent_level):\n",
    "        \"\"\"Write a single joint to the BVH file\"\"\"\n",
    "        indent = \"  \" * indent_level\n",
    "        \n",
    "        if joint.parent is None:\n",
    "            # Root joint\n",
    "            f.write(f\"{indent}ROOT {joint.name}\\n\")\n",
    "        else:\n",
    "            f.write(f\"{indent}JOINT {joint.name}\\n\")\n",
    "        \n",
    "        f.write(f\"{indent}{{\\n\")\n",
    "        \n",
    "        # Write offset\n",
    "        offset_str = \" \".join(map(lambda x: f\"{x:.6f}\", joint.offset))\n",
    "        f.write(f\"{indent}  OFFSET {offset_str}\\n\")\n",
    "        \n",
    "        # Write channels\n",
    "        channels_str = \" \".join(joint.channels)\n",
    "        f.write(f\"{indent}  CHANNELS {len(joint.channels)} {channels_str}\\n\")\n",
    "        \n",
    "        # Write children\n",
    "        for child in joint.children:\n",
    "            self._write_joint(f, child, indent_level + 1)\n",
    "        \n",
    "        # If this is an end site with no children, write an End Site\n",
    "        if not joint.children:\n",
    "            f.write(f\"{indent}  End Site\\n\")\n",
    "            f.write(f\"{indent}  {{\\n\")\n",
    "            # Typically end sites have a small positive Y offset\n",
    "            f.write(f\"{indent}    OFFSET 0.00 5.00 0.00\\n\")\n",
    "            f.write(f\"{indent}  }}\\n\")\n",
    "        \n",
    "        f.write(f\"{indent}}}\\n\")\n",
    "\n",
    "\n",
    "def process_video(input_file, output_file, visualize=False, debug=False, downsample_factor=1):\n",
    "    \"\"\"\n",
    "    Process a video file to extract pose data and convert to BVH\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to input video file\n",
    "        output_file: Path to output BVH file\n",
    "        visualize: Whether to show visualization\n",
    "        debug: Whether to print debug information\n",
    "        downsample_factor: Factor to downsample frames (1 = use all frames)\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    \n",
    "    # Create BVH skeleton\n",
    "    skeleton = BVHSkeleton()\n",
    "    \n",
    "    # Verify file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Error: Input file '{input_file}' does not exist.\")\n",
    "        return False\n",
    "    \n",
    "    # Open video file\n",
    "    print(f\"Opening video file: {input_file}\")\n",
    "    cap = cv2.VideoCapture(input_file)\n",
    "    \n",
    "    # Check if video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file '{input_file}'.\")\n",
    "        print(\"Supported formats include: mp4, avi, mov, etc.\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps <= 0:\n",
    "        fps = 30  # Default if unable to determine\n",
    "        print(f\"Warning: Could not determine video FPS, using default of {fps}\")\n",
    "    \n",
    "    # Set frame time accounting for downsampling\n",
    "    effective_fps = fps / downsample_factor\n",
    "    skeleton.frame_time = 1.0 / effective_fps\n",
    "    \n",
    "    # Count frames\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(f\"Video info: {width}x{height}, {fps} FPS, {total_frames} frames\")\n",
    "    if downsample_factor > 1:\n",
    "        print(f\"Downsampling: Using 1 frame per {downsample_factor} frames (effective FPS: {effective_fps:.2f})\")\n",
    "    \n",
    "    if total_frames <= 0:\n",
    "        print(\"Warning: Could not determine total frame count\")\n",
    "        total_frames = float('inf')  # Process until end of video\n",
    "    \n",
    "    # Initialize variables\n",
    "    frame_count = 0\n",
    "    processed_count = 0\n",
    "    is_first_frame_with_pose = True\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create the skeleton hierarchy\n",
    "    skeleton.create_hierarchy()\n",
    "    \n",
    "    # Setup Pose detection\n",
    "    print(\"Initializing MediaPipe pose detection...\")\n",
    "    \n",
    "    # Resolution affects performance, so choose model complexity wisely\n",
    "    if width * height <= 640 * 480:\n",
    "        model_complexity = 2  # Best accuracy for small videos\n",
    "    elif width * height <= 1280 * 720:\n",
    "        model_complexity = 1  # Balance for HD\n",
    "    else:\n",
    "        model_complexity = 1  # Performance for large videos\n",
    "    \n",
    "    pose_config = {\n",
    "        'static_image_mode': False,\n",
    "        'model_complexity': model_complexity,\n",
    "        'min_detection_confidence': 0.5,\n",
    "        'min_tracking_confidence': 0.5,\n",
    "        'smooth_landmarks': True\n",
    "    }\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"MediaPipe pose config: {pose_config}\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Process the video\n",
    "    with mp_pose.Pose(**pose_config) as pose:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Skip frames if downsampling\n",
    "            if downsample_factor > 1 and frame_count % downsample_factor != 0:\n",
    "                continue\n",
    "            \n",
    "            if debug or frame_count % 100 == 0:\n",
    "                print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "            \n",
    "            # Convert the BGR image to RGB\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # For better performance, mark the image as not writeable\n",
    "            image_rgb.flags.writeable = False\n",
    "            \n",
    "            # Process the image and detect pose\n",
    "            try:\n",
    "                results = pose.process(image_rgb)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing frame {frame_count}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Check if pose landmarks are detected\n",
    "            if results.pose_landmarks:\n",
    "                processed_count += 1\n",
    "                \n",
    "                # If this is the first frame with good landmarks, use it to initialize joint offsets\n",
    "                if is_first_frame_with_pose:\n",
    "                    print(\"First good pose detected! Initializing joint offsets...\")\n",
    "                    skeleton.update_joint_offsets(results.pose_landmarks.landmark)\n",
    "                    is_first_frame_with_pose = False\n",
    "                \n",
    "                # Process frame\n",
    "                try:\n",
    "                    motion_data = skeleton.process_frame(results.pose_landmarks.landmark)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing motion data for frame {frame_count}: {e}\")\n",
    "                    print(f\"Exception details: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Store frame data\n",
    "                channel_index = 0\n",
    "                for joint_name, joint in skeleton.joints.items():\n",
    "                    if not hasattr(joint, 'motion'):\n",
    "                        joint.motion = []\n",
    "                    \n",
    "                    # Extract just this joint's channels\n",
    "                    channel_count = len(joint.channels)\n",
    "                    joint_data = motion_data[channel_index:channel_index + channel_count]\n",
    "                    channel_index += channel_count\n",
    "                    \n",
    "                    joint.motion.append(joint_data)\n",
    "                \n",
    "                # Draw the pose landmarks for visualization\n",
    "                if visualize:\n",
    "                    image_rgb.flags.writeable = True\n",
    "                    \n",
    "                    # Draw pose landmarks\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image,\n",
    "                        results.pose_landmarks,\n",
    "                        mp_pose.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "                    )\n",
    "                    \n",
    "                    # Add frame info\n",
    "                    cv2.putText(\n",
    "                        image, f\"Frame: {frame_count}/{total_frames}\", \n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2\n",
    "                    )\n",
    "                    \n",
    "                    cv2.putText(\n",
    "                        image, f\"Processed: {processed_count} frames\", \n",
    "                        (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2\n",
    "                    )\n",
    "                    \n",
    "                    # Display the image\n",
    "\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    if visualize:\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    # Duration and statistics\n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nProcessing complete: {processed_count} frames with pose data out of {frame_count} total frames\")\n",
    "    print(f\"Time taken: {duration:.2f} seconds ({frame_count/duration:.2f} FPS)\")\n",
    "    \n",
    "    # Check if we have any processed frames\n",
    "    if processed_count == 0:\n",
    "        print(\"\\nERROR: No frames were successfully processed!\")\n",
    "        print(\"Possible issues:\")\n",
    "        print(\"1. The video doesn't contain a clearly visible person\")\n",
    "        print(\"2. The lighting conditions make pose detection difficult\")\n",
    "        print(\"3. The person is too small in the frame or too far from the camera\")\n",
    "        print(\"4. The video format might be incompatible\")\n",
    "        print(\"\\nTry with a different video or with the person closer to camera\")\n",
    "        return False\n",
    "    \n",
    "    # Set the total number of frames in the BVH file\n",
    "    skeleton.frames = processed_count\n",
    "    \n",
    "    # Write BVH file\n",
    "    try:\n",
    "        print(f\"Writing BVH file to {output_file}...\")\n",
    "        skeleton.write_bvh(output_file)\n",
    "        print(f\"BVH file written successfully with {processed_count} frames of motion data\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing BVH file: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02a1d36-190d-46bf-aabd-eb63e0caf42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening video file: fight2.mp4\n",
      "Video info: 1280x720, 30.0 FPS, 43 frames\n",
      "Initializing MediaPipe pose detection...\n",
      "First good pose detected! Initializing joint offsets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740617417.383400   26509 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1740617417.385594   26604 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1740617417.451052   26582 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740617417.483189   26584 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740617417.502588   26582 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete: 43 frames with pose data out of 43 total frames\n",
      "Time taken: 1.23 seconds (35.07 FPS)\n",
      "Writing BVH file to fight2.bvh...\n",
      "BVH file written successfully with 43 frames of motion data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"fight2\"\n",
    "process_video(f\"{filename}.mp4\", f\"{filename}.bvh\", True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35d07d-3ad9-4a5b-9326-4f9ab7a9137c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
