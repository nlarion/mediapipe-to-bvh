{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fec80b7-5fd0-4098-a4c9-2ca75043e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# MediaPipe setup\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "@dataclass\n",
    "class EmptyLandmark:\n",
    "    \"\"\"Simple class to substitute for MediaPipe landmarks when needed\"\"\"\n",
    "    x: float = 0.0\n",
    "    y: float = 0.0\n",
    "    z: float = 0.0\n",
    "    visibility: float = 0.0\n",
    "\n",
    "class Joint:\n",
    "    \"\"\"Class representing a joint in the BVH skeleton\"\"\"\n",
    "    def __init__(self, name, parent=None):\n",
    "        self.name = name\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.offset = np.zeros(3)\n",
    "        self.channels = []\n",
    "        self.rotation_order = 'XYZ'  # Using XYZ order for better Blender compatibility\n",
    "        \n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "        \n",
    "class MotionData:\n",
    "    \"\"\"Class to store motion data for the BVH file\"\"\"\n",
    "    def __init__(self, num_frames):\n",
    "        self.positions = {}  # Dict to store positions for each joint\n",
    "        self.rotations = {}  # Dict to store rotations for each joint\n",
    "        self.num_frames = num_frames\n",
    "        \n",
    "    def set_joint_position(self, frame, joint_name, position):\n",
    "        if joint_name not in self.positions:\n",
    "            self.positions[joint_name] = [np.zeros(3) for _ in range(self.num_frames)]\n",
    "        self.positions[joint_name][frame] = position\n",
    "        \n",
    "    def set_joint_rotation(self, frame, joint_name, rotation):\n",
    "        if joint_name not in self.rotations:\n",
    "            self.rotations[joint_name] = [np.zeros(3) for _ in range(self.num_frames)]\n",
    "        self.rotations[joint_name][frame] = rotation\n",
    "        \n",
    "    def get_joint_position(self, frame, joint_name):\n",
    "        return self.positions.get(joint_name, [np.zeros(3)])[frame]\n",
    "        \n",
    "    def get_joint_rotation(self, frame, joint_name):\n",
    "        return self.rotations.get(joint_name, [np.zeros(3)])[frame]\n",
    "\n",
    "def create_skeleton():\n",
    "    \"\"\"Create a skeleton structure that matches MediaPipe's pose landmarks.\"\"\"\n",
    "    # Root joint\n",
    "    hips = Joint(\"Hips\")\n",
    "    \n",
    "    # Spine\n",
    "    spine = Joint(\"Spine\", hips)\n",
    "    hips.add_child(spine)\n",
    "    \n",
    "    chest = Joint(\"Chest\", spine)\n",
    "    spine.add_child(chest)\n",
    "    \n",
    "    neck = Joint(\"Neck\", chest)\n",
    "    chest.add_child(neck)\n",
    "    \n",
    "    head = Joint(\"Head\", neck)\n",
    "    neck.add_child(head)\n",
    "    \n",
    "    # Left arm\n",
    "    left_shoulder = Joint(\"LeftShoulder\", chest)\n",
    "    chest.add_child(left_shoulder)\n",
    "    \n",
    "    left_arm = Joint(\"LeftArm\", left_shoulder)\n",
    "    left_shoulder.add_child(left_arm)\n",
    "    \n",
    "    left_forearm = Joint(\"LeftForeArm\", left_arm)\n",
    "    left_arm.add_child(left_forearm)\n",
    "    \n",
    "    left_hand = Joint(\"LeftHand\", left_forearm)\n",
    "    left_forearm.add_child(left_hand)\n",
    "    \n",
    "    # Right arm\n",
    "    right_shoulder = Joint(\"RightShoulder\", chest)\n",
    "    chest.add_child(right_shoulder)\n",
    "    \n",
    "    right_arm = Joint(\"RightArm\", right_shoulder)\n",
    "    right_shoulder.add_child(right_arm)\n",
    "    \n",
    "    right_forearm = Joint(\"RightForeArm\", right_arm)\n",
    "    right_arm.add_child(right_forearm)\n",
    "    \n",
    "    right_hand = Joint(\"RightHand\", right_forearm)\n",
    "    right_forearm.add_child(right_hand)\n",
    "    \n",
    "    # Left leg\n",
    "    left_up_leg = Joint(\"LeftUpLeg\", hips)\n",
    "    hips.add_child(left_up_leg)\n",
    "    \n",
    "    left_leg = Joint(\"LeftLeg\", left_up_leg)\n",
    "    left_up_leg.add_child(left_leg)\n",
    "    \n",
    "    left_foot = Joint(\"LeftFoot\", left_leg)\n",
    "    left_leg.add_child(left_foot)\n",
    "    \n",
    "    left_toe = Joint(\"LeftToeBase\", left_foot)\n",
    "    left_foot.add_child(left_toe)\n",
    "    \n",
    "    # Right leg\n",
    "    right_up_leg = Joint(\"RightUpLeg\", hips)\n",
    "    hips.add_child(right_up_leg)\n",
    "    \n",
    "    right_leg = Joint(\"RightLeg\", right_up_leg)\n",
    "    right_up_leg.add_child(right_leg)\n",
    "    \n",
    "    right_foot = Joint(\"RightFoot\", right_leg)\n",
    "    right_leg.add_child(right_foot)\n",
    "    \n",
    "    right_toe = Joint(\"RightToeBase\", right_foot)\n",
    "    right_foot.add_child(right_toe)\n",
    "    \n",
    "    return hips\n",
    "\n",
    "def get_mediapipe_landmark_indices():\n",
    "    \"\"\"Define the landmark indices in MediaPipe format\"\"\"\n",
    "    return {\n",
    "        \"hip_center\": [mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "        \"spine\": [mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.RIGHT_HIP, \n",
    "                  mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        \"chest\": [mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        \"neck\": [mp_pose.PoseLandmark.LEFT_EAR, mp_pose.PoseLandmark.RIGHT_EAR, \n",
    "                mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        \"head\": [mp_pose.PoseLandmark.NOSE, mp_pose.PoseLandmark.LEFT_EAR, mp_pose.PoseLandmark.RIGHT_EAR],\n",
    "        \n",
    "        \"left_shoulder\": [mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "        \"left_elbow\": [mp_pose.PoseLandmark.LEFT_ELBOW],\n",
    "        \"left_wrist\": [mp_pose.PoseLandmark.LEFT_WRIST],\n",
    "        \"left_hand\": [mp_pose.PoseLandmark.LEFT_PINKY, mp_pose.PoseLandmark.LEFT_INDEX, \n",
    "                     mp_pose.PoseLandmark.LEFT_THUMB],\n",
    "        \n",
    "        \"right_shoulder\": [mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        \"right_elbow\": [mp_pose.PoseLandmark.RIGHT_ELBOW],\n",
    "        \"right_wrist\": [mp_pose.PoseLandmark.RIGHT_WRIST],\n",
    "        \"right_hand\": [mp_pose.PoseLandmark.RIGHT_PINKY, mp_pose.PoseLandmark.RIGHT_INDEX, \n",
    "                      mp_pose.PoseLandmark.RIGHT_THUMB],\n",
    "        \n",
    "        \"left_hip\": [mp_pose.PoseLandmark.LEFT_HIP],\n",
    "        \"left_knee\": [mp_pose.PoseLandmark.LEFT_KNEE],\n",
    "        \"left_ankle\": [mp_pose.PoseLandmark.LEFT_ANKLE],\n",
    "        \"left_foot\": [mp_pose.PoseLandmark.LEFT_FOOT_INDEX, mp_pose.PoseLandmark.LEFT_HEEL],\n",
    "        \n",
    "        \"right_hip\": [mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "        \"right_knee\": [mp_pose.PoseLandmark.RIGHT_KNEE],\n",
    "        \"right_ankle\": [mp_pose.PoseLandmark.RIGHT_ANKLE],\n",
    "        \"right_foot\": [mp_pose.PoseLandmark.RIGHT_FOOT_INDEX, mp_pose.PoseLandmark.RIGHT_HEEL]\n",
    "    }\n",
    "\n",
    "def get_joint_mapping():\n",
    "    \"\"\"Map MediaPipe landmarks to BVH skeleton joints\"\"\"\n",
    "    mediapipe_indices = get_mediapipe_landmark_indices()\n",
    "    \n",
    "    return {\n",
    "        \"Hips\": mediapipe_indices[\"hip_center\"],\n",
    "        \"Spine\": mediapipe_indices[\"spine\"],\n",
    "        \"Chest\": mediapipe_indices[\"chest\"],\n",
    "        \"Neck\": mediapipe_indices[\"neck\"],\n",
    "        \"Head\": mediapipe_indices[\"head\"],\n",
    "        \n",
    "        \"LeftShoulder\": mediapipe_indices[\"left_shoulder\"],\n",
    "        \"LeftArm\": mediapipe_indices[\"left_elbow\"],\n",
    "        \"LeftForeArm\": mediapipe_indices[\"left_wrist\"],\n",
    "        \"LeftHand\": mediapipe_indices[\"left_hand\"],\n",
    "        \n",
    "        \"RightShoulder\": mediapipe_indices[\"right_shoulder\"],\n",
    "        \"RightArm\": mediapipe_indices[\"right_elbow\"],\n",
    "        \"RightForeArm\": mediapipe_indices[\"right_wrist\"],\n",
    "        \"RightHand\": mediapipe_indices[\"right_hand\"],\n",
    "        \n",
    "        \"LeftUpLeg\": mediapipe_indices[\"left_hip\"],\n",
    "        \"LeftLeg\": mediapipe_indices[\"left_knee\"],\n",
    "        \"LeftFoot\": mediapipe_indices[\"left_ankle\"],\n",
    "        \"LeftToeBase\": mediapipe_indices[\"left_foot\"],\n",
    "        \n",
    "        \"RightUpLeg\": mediapipe_indices[\"right_hip\"],\n",
    "        \"RightLeg\": mediapipe_indices[\"right_knee\"],\n",
    "        \"RightFoot\": mediapipe_indices[\"right_ankle\"],\n",
    "        \"RightToeBase\": mediapipe_indices[\"right_foot\"]\n",
    "    }\n",
    "\n",
    "def get_joint_connections():\n",
    "    \"\"\"Define parent-child connections for calculating rotations\"\"\"\n",
    "    return {\n",
    "        \"Hips\": [\"Spine\", \"LeftUpLeg\", \"RightUpLeg\"],\n",
    "        \"Spine\": [\"Chest\"],\n",
    "        \"Chest\": [\"Neck\", \"LeftShoulder\", \"RightShoulder\"],\n",
    "        \"Neck\": [\"Head\"],\n",
    "        \"Head\": [],\n",
    "        \n",
    "        \"LeftShoulder\": [\"LeftArm\"],\n",
    "        \"LeftArm\": [\"LeftForeArm\"],\n",
    "        \"LeftForeArm\": [\"LeftHand\"],\n",
    "        \"LeftHand\": [],\n",
    "        \n",
    "        \"RightShoulder\": [\"RightArm\"],\n",
    "        \"RightArm\": [\"RightForeArm\"],\n",
    "        \"RightForeArm\": [\"RightHand\"],\n",
    "        \"RightHand\": [],\n",
    "        \n",
    "        \"LeftUpLeg\": [\"LeftLeg\"],\n",
    "        \"LeftLeg\": [\"LeftFoot\"],\n",
    "        \"LeftFoot\": [\"LeftToeBase\"],\n",
    "        \"LeftToeBase\": [],\n",
    "        \n",
    "        \"RightUpLeg\": [\"RightLeg\"],\n",
    "        \"RightLeg\": [\"RightFoot\"],\n",
    "        \"RightFoot\": [\"RightToeBase\"],\n",
    "        \"RightToeBase\": []\n",
    "    }\n",
    "\n",
    "def get_parent_joint(joint_name):\n",
    "    \"\"\"Get parent joint name for given joint\"\"\"\n",
    "    connections = get_joint_connections()\n",
    "    \n",
    "    for parent, children in connections.items():\n",
    "        if joint_name in children:\n",
    "            return parent\n",
    "    \n",
    "    return None  # No parent (root)\n",
    "\n",
    "def get_landmark_position(landmarks, idx):\n",
    "    \"\"\"Safely get the position of a landmark by index\"\"\"\n",
    "    if landmarks and idx < len(landmarks):\n",
    "        lm = landmarks[idx]\n",
    "        if hasattr(lm, 'x') and hasattr(lm, 'y') and hasattr(lm, 'z'):\n",
    "            if not (np.isnan(lm.x) or np.isnan(lm.y) or np.isnan(lm.z)):\n",
    "                return np.array([lm.x, lm.y, lm.z])\n",
    "    return None\n",
    "\n",
    "def get_average_landmark_position(landmarks, indices):\n",
    "    \"\"\"Get average position from multiple landmark indices\"\"\"\n",
    "    positions = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        pos = get_landmark_position(landmarks, idx)\n",
    "        if pos is not None:\n",
    "            positions.append(pos)\n",
    "    \n",
    "    if positions:\n",
    "        return np.mean(positions, axis=0)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_joint_positions(frame_landmarks, joint_mapping):\n",
    "    \"\"\"Extract joint positions from landmarks for the current frame\"\"\"\n",
    "    joint_positions = {}\n",
    "    \n",
    "    for joint_name, indices in joint_mapping.items():\n",
    "        pos = get_average_landmark_position(frame_landmarks, indices)\n",
    "        if pos is not None:\n",
    "            # MediaPipe coordinate system: X right, Y down, Z forward (from camera)\n",
    "            # Convert to BVH coordinate system: X right, Y up, Z forward\n",
    "            pos_bvh = np.array([pos[0], -pos[1], pos[2]])\n",
    "            joint_positions[joint_name] = pos_bvh\n",
    "    \n",
    "    return joint_positions\n",
    "\n",
    "def interpolate_missing_joints(joint_positions, connections):\n",
    "    \"\"\"Fill in missing joints using interpolation from parent to child\"\"\"\n",
    "    all_joints = list(connections.keys())\n",
    "    filled_positions = joint_positions.copy()\n",
    "    \n",
    "    # Multiple passes to handle multi-level interpolation\n",
    "    for _ in range(3):\n",
    "        for joint in all_joints:\n",
    "            if joint not in filled_positions:\n",
    "                parent = get_parent_joint(joint)\n",
    "                children = connections.get(joint, [])\n",
    "                \n",
    "                # If parent and at least one child are available, interpolate\n",
    "                if parent and parent in filled_positions:\n",
    "                    child_positions = []\n",
    "                    for child in children:\n",
    "                        if child in filled_positions:\n",
    "                            child_positions.append(filled_positions[child])\n",
    "                    \n",
    "                    if child_positions:\n",
    "                        # Average position of all available children\n",
    "                        avg_child = np.mean(child_positions, axis=0)\n",
    "                        # Interpolate halfway between parent and average child\n",
    "                        filled_positions[joint] = (filled_positions[parent] + avg_child) / 2\n",
    "                \n",
    "                # Or if just parent is available, estimate\n",
    "                elif parent and parent in filled_positions:\n",
    "                    # Estimate based on parent and joint type\n",
    "                    parent_pos = filled_positions[parent]\n",
    "                    \n",
    "                    # Custom offsets based on joint types\n",
    "                    if \"UpLeg\" in joint:\n",
    "                        # Hips to upper leg: down and out\n",
    "                        direction = np.array([0.1 if \"Right\" in joint else -0.1, -0.1, 0])\n",
    "                    elif \"Leg\" in joint:\n",
    "                        # Upper leg to lower leg: down\n",
    "                        direction = np.array([0, -0.15, 0])\n",
    "                    elif \"Foot\" in joint:\n",
    "                        # Leg to foot: down and forward\n",
    "                        direction = np.array([0, -0.1, 0.05])\n",
    "                    elif \"Toe\" in joint:\n",
    "                        # Foot to toe: forward\n",
    "                        direction = np.array([0, -0.05, 0.1])\n",
    "                    elif \"Shoulder\" in joint:\n",
    "                        # Chest to shoulder: out\n",
    "                        direction = np.array([0.1 if \"Right\" in joint else -0.1, 0, 0])\n",
    "                    elif \"Arm\" in joint and not \"Fore\" in joint:\n",
    "                        # Shoulder to arm: out\n",
    "                        direction = np.array([0.1 if \"Right\" in joint else -0.1, -0.02, 0])\n",
    "                    elif \"ForeArm\" in joint:\n",
    "                        # Arm to forearm: out and down\n",
    "                        direction = np.array([0.1 if \"Right\" in joint else -0.1, -0.02, 0])\n",
    "                    elif \"Hand\" in joint:\n",
    "                        # Forearm to hand: out\n",
    "                        direction = np.array([0.08 if \"Right\" in joint else -0.08, 0, 0])\n",
    "                    elif joint == \"Head\":\n",
    "                        # Neck to head: up\n",
    "                        direction = np.array([0, 0.1, 0])\n",
    "                    elif joint == \"Neck\":\n",
    "                        # Chest to neck: up\n",
    "                        direction = np.array([0, 0.1, 0])\n",
    "                    elif joint == \"Chest\":\n",
    "                        # Spine to chest: up\n",
    "                        direction = np.array([0, 0.15, 0])\n",
    "                    elif joint == \"Spine\":\n",
    "                        # Hips to spine: up\n",
    "                        direction = np.array([0, 0.1, 0])\n",
    "                    else:\n",
    "                        # Default: small upward direction\n",
    "                        direction = np.array([0, 0.1, 0])\n",
    "                    \n",
    "                    filled_positions[joint] = parent_pos + direction\n",
    "    \n",
    "    return filled_positions\n",
    "\n",
    "def calculate_joint_offsets(skeleton, reference_frame_positions):\n",
    "    \"\"\"Calculate joint offsets for the skeleton based on a reference frame\"\"\"\n",
    "    def process_joint(joint):\n",
    "        if joint.parent:\n",
    "            # If both this joint and parent are in the reference frame\n",
    "            if joint.name in reference_frame_positions and joint.parent.name in reference_frame_positions:\n",
    "                parent_pos = reference_frame_positions[joint.parent.name]\n",
    "                joint_pos = reference_frame_positions[joint.name]\n",
    "                joint.offset = joint_pos - parent_pos\n",
    "            else:\n",
    "                # Use default offsets if not in reference frame\n",
    "                if \"Left\" in joint.name:\n",
    "                    joint.offset = np.array([-0.1, 0, 0])\n",
    "                elif \"Right\" in joint.name:\n",
    "                    joint.offset = np.array([0.1, 0, 0])\n",
    "                elif \"Head\" in joint.name:\n",
    "                    joint.offset = np.array([0, 0.1, 0])\n",
    "                elif \"Neck\" in joint.name:\n",
    "                    joint.offset = np.array([0, 0.08, 0])\n",
    "                elif \"Chest\" in joint.name:\n",
    "                    joint.offset = np.array([0, 0.15, 0])\n",
    "                elif \"Spine\" in joint.name:\n",
    "                    joint.offset = np.array([0, 0.15, 0])\n",
    "                elif \"Toe\" in joint.name:\n",
    "                    joint.offset = np.array([0, 0, 0.1])\n",
    "                else:\n",
    "                    joint.offset = np.array([0, 0.1, 0])\n",
    "            \n",
    "            # Ensure non-zero offset (critical for Blender)\n",
    "            if np.linalg.norm(joint.offset) < 0.01:\n",
    "                if \"Left\" in joint.name:\n",
    "                    joint.offset = np.array([-0.1, 0, 0])\n",
    "                elif \"Right\" in joint.name:\n",
    "                    joint.offset = np.array([0.1, 0, 0])\n",
    "                elif \"Head\" in joint.name:\n",
    "                    joint.offset = np.array([0, 0.1, 0])\n",
    "                elif \"Hand\" in joint.name:\n",
    "                    if \"Left\" in joint.name:\n",
    "                        joint.offset = np.array([-0.1, 0, 0])\n",
    "                    else:\n",
    "                        joint.offset = np.array([0.1, 0, 0])\n",
    "                elif \"Foot\" in joint.name:\n",
    "                    joint.offset = np.array([0, -0.1, 0.05])\n",
    "                else:\n",
    "                    joint.offset = np.array([0, 0.1, 0])\n",
    "        else:\n",
    "            # Root joint has no offset\n",
    "            joint.offset = np.array([0, 0, 0])\n",
    "        \n",
    "        # Scale the offset to reasonable size\n",
    "        joint.offset *= 10.0  # Scale factor can be adjusted\n",
    "        \n",
    "        for child in joint.children:\n",
    "            process_joint(child)\n",
    "    \n",
    "    process_joint(skeleton)\n",
    "\n",
    "def vector_to_euler(forward, up, order='XYZ'):\n",
    "    \"\"\"Convert forward and up vectors to Euler angles\"\"\"\n",
    "    # Make sure vectors are normalized\n",
    "    forward = forward / np.linalg.norm(forward)\n",
    "    up = up / np.linalg.norm(up)\n",
    "    \n",
    "    # Get the third perpendicular axis (right vector)\n",
    "    right = np.cross(forward, up)\n",
    "    right = right / np.linalg.norm(right)\n",
    "    \n",
    "    # Rebuild the up vector to ensure orthogonality\n",
    "    up = np.cross(right, forward)\n",
    "    \n",
    "    # Create rotation matrix\n",
    "    rotation_matrix = np.array([\n",
    "        [right[0], up[0], forward[0]],\n",
    "        [right[1], up[1], forward[1]],\n",
    "        [right[2], up[2], forward[2]]\n",
    "    ])\n",
    "    \n",
    "    # Convert rotation matrix to Euler angles\n",
    "    if order == 'XYZ':\n",
    "        # Extract Euler angles\n",
    "        sy = math.sqrt(rotation_matrix[0, 0] * rotation_matrix[0, 0] + rotation_matrix[1, 0] * rotation_matrix[1, 0])\n",
    "        \n",
    "        if sy > 1e-6:\n",
    "            x = math.atan2(rotation_matrix[2, 1], rotation_matrix[2, 2])\n",
    "            y = math.atan2(-rotation_matrix[2, 0], sy)\n",
    "            z = math.atan2(rotation_matrix[1, 0], rotation_matrix[0, 0])\n",
    "        else:\n",
    "            x = math.atan2(-rotation_matrix[1, 2], rotation_matrix[1, 1])\n",
    "            y = math.atan2(-rotation_matrix[2, 0], sy)\n",
    "            z = 0\n",
    "    else:\n",
    "        # Handle other rotation orders if needed\n",
    "        x, y, z = 0, 0, 0\n",
    "    \n",
    "    return np.array([math.degrees(x), math.degrees(y), math.degrees(z)])\n",
    "\n",
    "def calculate_bone_direction(joint_positions, joint_name, child_name):\n",
    "    \"\"\"Calculate normalized direction vector from joint to child\"\"\"\n",
    "    if joint_name in joint_positions and child_name in joint_positions:\n",
    "        start = joint_positions[joint_name]\n",
    "        end = joint_positions[child_name]\n",
    "        direction = end - start\n",
    "        length = np.linalg.norm(direction)\n",
    "        \n",
    "        if length > 1e-10:\n",
    "            return direction / length\n",
    "    \n",
    "    return None\n",
    "\n",
    "def calculate_joint_rotations(joint_positions, connections):\n",
    "    \"\"\"Calculate joint rotations based on the positions of connected joints\"\"\"\n",
    "    joint_rotations = {}\n",
    "    \n",
    "    for joint_name, children in connections.items():\n",
    "        if joint_name not in joint_positions or not children:\n",
    "            continue\n",
    "        \n",
    "        # Find at least one connected child\n",
    "        child_directions = []\n",
    "        for child in children:\n",
    "            if child in joint_positions:\n",
    "                direction = calculate_bone_direction(joint_positions, joint_name, child)\n",
    "                if direction is not None:\n",
    "                    child_directions.append((child, direction))\n",
    "        \n",
    "        if not child_directions:\n",
    "            continue\n",
    "        \n",
    "        # Use the first child for primary direction\n",
    "        primary_child, forward = child_directions[0]\n",
    "        \n",
    "        # Determine up vector based on joint context\n",
    "        up = np.array([0, 1, 0])  # Default up\n",
    "        \n",
    "        # For limbs, use a more anatomically appropriate up vector\n",
    "        if \"Arm\" in joint_name or \"ForeArm\" in joint_name:\n",
    "            # For arms, \"up\" depends on left/right\n",
    "            if \"Left\" in joint_name:\n",
    "                up = np.array([0, 0, -1])  # Left arm: up is backward\n",
    "            else:\n",
    "                up = np.array([0, 0, -1])  # Right arm: up is backward\n",
    "        elif \"UpLeg\" in joint_name or \"Leg\" in joint_name:\n",
    "            # For legs, \"up\" points forward\n",
    "            up = np.array([0, 0, 1])\n",
    "        elif joint_name in [\"Spine\", \"Chest\", \"Neck\"]:\n",
    "            # For spine/chest/neck, \"up\" depends on context\n",
    "            # Try to use left/right directions to determine orientation\n",
    "            if \"LeftShoulder\" in joint_positions and \"RightShoulder\" in joint_positions:\n",
    "                left = joint_positions[\"LeftShoulder\"] - joint_positions[joint_name]\n",
    "                right = joint_positions[\"RightShoulder\"] - joint_positions[joint_name]\n",
    "                front_cross = np.cross(right, left)\n",
    "                if np.linalg.norm(front_cross) > 1e-10:\n",
    "                    up = front_cross / np.linalg.norm(front_cross)\n",
    "        \n",
    "        # Make sure up is perpendicular to forward\n",
    "        up = up - np.dot(up, forward) * forward\n",
    "        if np.linalg.norm(up) > 1e-10:\n",
    "            up = up / np.linalg.norm(up)\n",
    "        else:\n",
    "            # If up became zero, find a new perpendicular vector\n",
    "            if abs(forward[0]) < abs(forward[1]):\n",
    "                up = np.cross(forward, np.array([1, 0, 0]))\n",
    "            else:\n",
    "                up = np.cross(forward, np.array([0, 1, 0]))\n",
    "            \n",
    "            if np.linalg.norm(up) > 1e-10:\n",
    "                up = up / np.linalg.norm(up)\n",
    "        \n",
    "        # Convert to Euler angles\n",
    "        euler = vector_to_euler(forward, up)\n",
    "        joint_rotations[joint_name] = euler\n",
    "    \n",
    "    return joint_rotations\n",
    "\n",
    "def smooth_rotations(all_frame_rotations, window=5):\n",
    "    \"\"\"Apply a moving average filter to smooth rotations\"\"\"\n",
    "    joints = all_frame_rotations[0].keys()\n",
    "    num_frames = len(all_frame_rotations)\n",
    "    \n",
    "    smoothed_rotations = [{} for _ in range(num_frames)]\n",
    "    \n",
    "    for joint in joints:\n",
    "        # Extract this joint's rotations across all frames\n",
    "        joint_rots = np.array([frame.get(joint, np.zeros(3)) for frame in all_frame_rotations])\n",
    "        \n",
    "        # Apply moving average filter\n",
    "        smoothed_joint_rots = np.copy(joint_rots)\n",
    "        half_window = window // 2\n",
    "        \n",
    "        for i in range(num_frames):\n",
    "            start = max(0, i - half_window)\n",
    "            end = min(num_frames, i + half_window + 1)\n",
    "            \n",
    "            # Use weighted average (center frame has more weight)\n",
    "            weights = np.ones(end - start)\n",
    "            center_idx = i - start\n",
    "            if center_idx >= 0 and center_idx < len(weights):\n",
    "                weights[center_idx] = 2.0  # Higher weight for center frame\n",
    "            \n",
    "            weights = weights / np.sum(weights)\n",
    "            \n",
    "            # Weighted average for each axis\n",
    "            for axis in range(3):\n",
    "                smoothed_joint_rots[i, axis] = np.sum(joint_rots[start:end, axis] * weights)\n",
    "        \n",
    "        # Store smoothed rotations\n",
    "        for i in range(num_frames):\n",
    "            smoothed_rotations[i][joint] = smoothed_joint_rots[i]\n",
    "    \n",
    "    return smoothed_rotations\n",
    "\n",
    "def write_bvh_file(skeleton, all_frame_rotations, frame_time, output_file):\n",
    "    \"\"\"Write the BVH file with motion data\"\"\"\n",
    "    print(f\"Writing BVH file to {output_file}...\")\n",
    "    try:\n",
    "        with open(output_file, 'w') as f:\n",
    "            # Write header\n",
    "            f.write(\"HIERARCHY\\n\")\n",
    "            \n",
    "            # Write joint hierarchy recursively\n",
    "            write_joint_hierarchy(f, skeleton, 0)\n",
    "            \n",
    "            # Write motion data\n",
    "            num_frames = len(all_frame_rotations)\n",
    "            f.write(\"MOTION\\n\")\n",
    "            f.write(f\"Frames: {num_frames}\\n\")\n",
    "            f.write(f\"Frame Time: {frame_time:.6f}\\n\")\n",
    "            \n",
    "            # Extract hip positions and rotations for all frames\n",
    "            hip_positions = np.zeros((num_frames, 3))\n",
    "            \n",
    "            # For each frame, write data\n",
    "            for frame_idx in tqdm(range(num_frames), desc=\"Writing animation data\"):\n",
    "                frame_data = []\n",
    "                frame_rotations = all_frame_rotations[frame_idx]\n",
    "                \n",
    "                # Root position (track position changes)\n",
    "                frame_data.extend(hip_positions[frame_idx])\n",
    "                \n",
    "                # Write rotations for all joints in depth-first order\n",
    "                write_joint_rotations(skeleton, frame_rotations, frame_data)\n",
    "                \n",
    "                f.write(\" \".join([f\"{val:.6f}\" for val in frame_data]) + \"\\n\")\n",
    "                \n",
    "        print(f\"BVH file created successfully: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing BVH file: {e}\")\n",
    "\n",
    "def write_joint_hierarchy(f, joint, indent_level):\n",
    "    \"\"\"Write the joint hierarchy recursively to the BVH file\"\"\"\n",
    "    indent = \"  \" * indent_level\n",
    "    \n",
    "    if joint.parent is None:\n",
    "        # Root joint\n",
    "        f.write(f\"{indent}ROOT {joint.name}\\n\")\n",
    "    else:\n",
    "        # Child joint\n",
    "        f.write(f\"{indent}JOINT {joint.name}\\n\")\n",
    "    \n",
    "    f.write(f\"{indent}\" + \"{\\n\")\n",
    "    \n",
    "    # Write offset\n",
    "    f.write(f\"{indent}  OFFSET {joint.offset[0]:.6f} {joint.offset[1]:.6f} {joint.offset[2]:.6f}\\n\")\n",
    "    \n",
    "    # Write channels\n",
    "    if joint.parent is None:\n",
    "        # Root has 6 channels: position and rotation\n",
    "        f.write(f\"{indent}  CHANNELS 6 Xposition Yposition Zposition {joint.rotation_order[0]}rotation {joint.rotation_order[1]}rotation {joint.rotation_order[2]}rotation\\n\")\n",
    "    else:\n",
    "        # Other joints have 3 channels: rotation only\n",
    "        f.write(f\"{indent}  CHANNELS 3 {joint.rotation_order[0]}rotation {joint.rotation_order[1]}rotation {joint.rotation_order[2]}rotation\\n\")\n",
    "    \n",
    "    # Process children\n",
    "    for child in joint.children:\n",
    "        write_joint_hierarchy(f, child, indent_level + 1)\n",
    "    \n",
    "    # If no children, write end site\n",
    "    if not joint.children:\n",
    "        f.write(f\"{indent}  End Site\\n\")\n",
    "        f.write(f\"{indent}  \" + \"{\\n\")\n",
    "        \n",
    "        # Use a non-zero offset for end sites\n",
    "        if \"Hand\" in joint.name:\n",
    "            # Extend in the appropriate direction\n",
    "            if \"Left\" in joint.name:\n",
    "                f.write(f\"{indent}    OFFSET -5.0 0.0 0.0\\n\")\n",
    "            else:\n",
    "                f.write(f\"{indent}    OFFSET 5.0 0.0 0.0\\n\")\n",
    "        elif \"Toe\" in joint.name:\n",
    "            f.write(f\"{indent}    OFFSET 0.0 0.0 5.0\\n\")  # Forward\n",
    "        elif \"Head\" in joint.name:\n",
    "            f.write(f\"{indent}    OFFSET 0.0 5.0 0.0\\n\")  # Upward\n",
    "        else:\n",
    "            f.write(f\"{indent}    OFFSET 0.0 3.0 0.0\\n\")  # Default upward\n",
    "        \n",
    "        f.write(f\"{indent}  \" + \"}\\n\")\n",
    "    \n",
    "    f.write(f\"{indent}\" + \"}\\n\")\n",
    "\n",
    "def write_joint_rotations(joint, frame_rotations, frame_data):\n",
    "    \"\"\"Write rotations for a joint and its children recursively\"\"\"\n",
    "    # Add this joint's rotation\n",
    "    if joint.name in frame_rotations:\n",
    "        frame_data.extend(frame_rotations[joint.name])\n",
    "    else:\n",
    "        # Default to zero rotation if not found\n",
    "        frame_data.extend([0.0, 0.0, 0.0])\n",
    "    \n",
    "    # Process all children in order\n",
    "    for child in joint.children:\n",
    "        write_joint_rotations(child, frame_rotations, frame_data)\n",
    "\n",
    "def get_all_joints(skeleton):\n",
    "    \"\"\"Get a list of all joints in the skeleton\"\"\"\n",
    "    joints = []\n",
    "    \n",
    "    def collect_joints(joint):\n",
    "        joints.append(joint)\n",
    "        for child in joint.children:\n",
    "            collect_joints(child)\n",
    "    \n",
    "    collect_joints(skeleton)\n",
    "    return joints\n",
    "\n",
    "def render_skeleton_preview(frame_landmarks, frame, output_dir, frame_idx, joint_positions=None):\n",
    "    \"\"\"Render a preview image of the detected skeleton\"\"\"\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    \n",
    "    # Draw the pose annotation on the image\n",
    "    annotated_image = frame.copy()\n",
    "    \n",
    "    # First, draw the MediaPipe skeleton\n",
    "    mp_drawing.draw_landmarks(\n",
    "        annotated_image,\n",
    "        frame_landmarks,\n",
    "        mp_pose.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "    \n",
    "    # If we have joint positions, draw our calculated bones\n",
    "    if joint_positions:\n",
    "        connections = get_joint_connections()\n",
    "        for joint_name, children in connections.items():\n",
    "            if joint_name in joint_positions:\n",
    "                start_pos = joint_positions[joint_name]\n",
    "                \n",
    "                # Convert to image coordinates (estimated)\n",
    "                start_x = int((start_pos[0] + 0.5) * annotated_image.shape[1])\n",
    "                start_y = int((-start_pos[1] + 0.5) * annotated_image.shape[0])\n",
    "                \n",
    "                for child in children:\n",
    "                    if child in joint_positions:\n",
    "                        end_pos = joint_positions[child]\n",
    "                        \n",
    "                        # Convert to image coordinates\n",
    "                        end_x = int((end_pos[0] + 0.5) * annotated_image.shape[1])\n",
    "                        end_y = int((-end_pos[1] +.5) * annotated_image.shape[0])\n",
    "                        \n",
    "                        # Draw this bone with a different color\n",
    "                        cv2.line(annotated_image, (start_x, start_y), (end_x, end_y), (0, 255, 0), 2)\n",
    "    \n",
    "    # Save the annotated image\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"frame_{frame_idx:04d}.png\"), annotated_image)\n",
    "\n",
    "def process_video(video_path, output_bvh, confidence_threshold=0.5, sample_rate=1, preview=False):\n",
    "    \"\"\"Process video and create BVH file\"\"\"\n",
    "    print(f\"Opening video file: {video_path}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(f\"Video properties: {width}x{height}, {fps} FPS, {frame_count} frames\")\n",
    "    print(f\"Sampling every {sample_rate} frames, resulting in approximately {frame_count//sample_rate} animation frames\")\n",
    "    \n",
    "    # Calculate frame time based on original FPS and sampling rate\n",
    "    frame_time = 1.0 / (fps / sample_rate)\n",
    "    \n",
    "    # Create output dirs if needed\n",
    "    preview_dir = os.path.splitext(output_bvh)[0] + \"_preview\"\n",
    "    if preview:\n",
    "        os.makedirs(preview_dir, exist_ok=True)\n",
    "    \n",
    "    # Create pose detector\n",
    "    print(\"Initializing MediaPipe Pose detector...\")\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=False,          # Video mode\n",
    "        model_complexity=1,               # Balanced accuracy and speed\n",
    "        smooth_landmarks=True,            # Enable temporal smoothing\n",
    "        enable_segmentation=False,        # No need for segmentation\n",
    "        smooth_segmentation=False,\n",
    "        min_detection_confidence=0.5,     # Initial detection confidence\n",
    "        min_tracking_confidence=0.5       # Tracking confidence between frames\n",
    "    ) as pose:\n",
    "        \n",
    "        # Process frames\n",
    "        all_landmarks = []\n",
    "        all_frames = []  # Store frames for preview if needed\n",
    "        frame_idx = 0\n",
    "        sampled_frames = 0\n",
    "        \n",
    "        print(f\"Processing video frames (sampling every {sample_rate} frames)...\")\n",
    "        \n",
    "        with tqdm(total=frame_count) as pbar:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Process only every sample_rate frames\n",
    "                if frame_idx % sample_rate == 0:\n",
    "                    # Convert BGR to RGB\n",
    "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    # Process the frame\n",
    "                    results = pose.process(frame_rgb)\n",
    "                    \n",
    "                    if results.pose_landmarks:\n",
    "                        # Store landmarks and original frame (if preview enabled)\n",
    "                        all_landmarks.append(results.pose_landmarks)\n",
    "                        if preview:\n",
    "                            all_frames.append(frame)\n",
    "                        sampled_frames += 1\n",
    "                    else:\n",
    "                        # If no landmarks detected, use empty landmarks\n",
    "                        empty_landmarks = mp.solutions.pose.PoseLandmark(33)  # Create empty landmarks\n",
    "                        all_landmarks.append(empty_landmarks)\n",
    "                        if preview:\n",
    "                            all_frames.append(frame)\n",
    "                        print(f\"Warning: No pose detected in frame {frame_idx}. Using empty landmarks.\")\n",
    "                \n",
    "                frame_idx += 1\n",
    "                pbar.update(1)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        if not all_landmarks:\n",
    "            print(\"Error: No frames with detected poses found in the video.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Video processing complete. Collected {len(all_landmarks)} frames of pose data.\")\n",
    "        \n",
    "        # Extract joint mapping\n",
    "        joint_mapping = get_joint_mapping()\n",
    "        connections = get_joint_connections()\n",
    "        \n",
    "        # Find a good reference frame for the skeleton structure\n",
    "        print(\"Finding a good reference frame for skeletal structure...\")\n",
    "        ref_frame_idx = 0\n",
    "        best_detection_score = 0\n",
    "        \n",
    "        for i in range(min(len(all_landmarks), 30)):  # Check first 30 frames at most\n",
    "            # Count how many key landmarks are detected\n",
    "            landmarks = all_landmarks[i]\n",
    "            if not hasattr(landmarks, 'landmark'):\n",
    "                continue\n",
    "                \n",
    "            detection_score = sum(lm.visibility > 0.5 for lm in landmarks.landmark if hasattr(lm, 'visibility'))\n",
    "            \n",
    "            if detection_score > best_detection_score:\n",
    "                best_detection_score = detection_score\n",
    "                ref_frame_idx = i\n",
    "                \n",
    "                # If all key points detected well, break early\n",
    "                if detection_score > 25:  # MediaPipe has 33 landmarks total\n",
    "                    break\n",
    "        \n",
    "        print(f\"Using frame {ref_frame_idx} for skeletal structure (detection score: {best_detection_score}/33)\")\n",
    "        \n",
    "        # Process all frames to extract positions\n",
    "        all_frame_positions = []\n",
    "        all_joint_rotations = []\n",
    "        \n",
    "        for i, landmarks in enumerate(tqdm(all_landmarks, desc=\"Processing motion data\")):\n",
    "            # Skip frames with bad detection\n",
    "            if not hasattr(landmarks, 'landmark'):\n",
    "                # If this is the first frame, we can't continue\n",
    "                if i == 0:\n",
    "                    print(\"Error: First frame has no valid landmarks. Cannot continue.\")\n",
    "                    return\n",
    "                \n",
    "                # Otherwise, reuse the previous frame\n",
    "                all_frame_positions.append(all_frame_positions[-1])\n",
    "                all_joint_rotations.append(all_joint_rotations[-1])\n",
    "                continue\n",
    "            \n",
    "            # Extract joint positions from landmarks\n",
    "            joint_positions = get_joint_positions(landmarks.landmark, joint_mapping)\n",
    "            \n",
    "            # Interpolate missing joints\n",
    "            joint_positions = interpolate_missing_joints(joint_positions, connections)\n",
    "            \n",
    "            # Calculate joint rotations\n",
    "            joint_rotations = calculate_joint_rotations(joint_positions, connections)\n",
    "            \n",
    "            # Save for this frame\n",
    "            all_frame_positions.append(joint_positions)\n",
    "            all_joint_rotations.append(joint_rotations)\n",
    "            \n",
    "            # Generate preview frame if enabled\n",
    "            if preview:\n",
    "                render_skeleton_preview(landmarks, all_frames[i], preview_dir, i, joint_positions)\n",
    "        \n",
    "        # Create skeleton structure\n",
    "        skeleton = create_skeleton()\n",
    "        \n",
    "        # Calculate joint offsets from the reference frame\n",
    "        reference_positions = all_frame_positions[ref_frame_idx]\n",
    "        calculate_joint_offsets(skeleton, reference_positions)\n",
    "        \n",
    "        # Smooth rotations to reduce jitter\n",
    "        print(\"Smoothing rotations...\")\n",
    "        smoothed_rotations = smooth_rotations(all_joint_rotations, window=5)\n",
    "        \n",
    "        # Write BVH file\n",
    "        write_bvh_file(skeleton, smoothed_rotations, frame_time, output_bvh)\n",
    "\n",
    "# def main():\n",
    "#     parser = argparse.ArgumentParser(description=\"Convert video to BVH using MediaPipe\")\n",
    "#     parser.add_argument(\"--video\", required=True, help=\"Path to input video file\")\n",
    "#     parser.add_argument(\"--output\", required=True, help=\"Path to output BVH file\")\n",
    "#     parser.add_argument(\"--confidence\", type=float, default=0.5, help=\"Confidence threshold for pose detection\")\n",
    "#     parser.add_argument(\"--sample-rate\", type=int, default=2, help=\"Process every Nth frame\")\n",
    "#     parser.add_argument(\"--preview\", action=\"store_true\", help=\"Generate preview images\")\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     print(\"Starting MediaPipe to BVH conversion...\")\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     process_video(args.video, args.output, args.confidence, args.sample_rate, args.preview)\n",
    "    \n",
    "#     end_time = time.time()\n",
    "#     print(f\"Conversion completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b35167-e7dc-429c-97a7-bdba77dab3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740686747.616388   33277 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening video file: cxk.mp4\n",
      "Video properties: 1920x1080, 60.0 FPS, 900 frames\n",
      "Sampling every 2 frames, resulting in approximately 450 animation frames\n",
      "Initializing MediaPipe Pose detector...\n",
      "Processing video frames (sampling every 2 frames)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740686747.617148   35745 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "  0%|                                                   | 0/900 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1740686747.707506   35736 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740686747.749877   35735 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "100%|█████████████████████████████████████████| 900/900 [00:16<00:00, 54.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processing complete. Collected 450 frames of pose data.\n",
      "Finding a good reference frame for skeletal structure...\n",
      "Using frame 0 for skeletal structure (detection score: 33/33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing motion data: 100%|█████████████████| 450/450 [00:26<00:00, 17.09it/s]\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'multiply' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcxk\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.bvh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# process_video(args.video, args.output, args.confidence, args.sample_rate)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 866\u001b[0m, in \u001b[0;36mprocess_video\u001b[0;34m(video_path, output_bvh, confidence_threshold, sample_rate, preview)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m# Calculate joint offsets from the reference frame\u001b[39;00m\n\u001b[1;32m    865\u001b[0m reference_positions \u001b[38;5;241m=\u001b[39m all_frame_positions[ref_frame_idx]\n\u001b[0;32m--> 866\u001b[0m \u001b[43mcalculate_joint_offsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskeleton\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_positions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Smooth rotations to reduce jitter\u001b[39;00m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSmoothing rotations...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 405\u001b[0m, in \u001b[0;36mcalculate_joint_offsets\u001b[0;34m(skeleton, reference_frame_positions)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m joint\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[1;32m    403\u001b[0m         process_joint(child)\n\u001b[0;32m--> 405\u001b[0m \u001b[43mprocess_joint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskeleton\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 400\u001b[0m, in \u001b[0;36mcalculate_joint_offsets.<locals>.process_joint\u001b[0;34m(joint)\u001b[0m\n\u001b[1;32m    397\u001b[0m     joint\u001b[38;5;241m.\u001b[39moffset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# Scale the offset to reasonable size\u001b[39;00m\n\u001b[0;32m--> 400\u001b[0m joint\u001b[38;5;241m.\u001b[39moffset \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m  \u001b[38;5;66;03m# Scale factor can be adjusted\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m joint\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[1;32m    403\u001b[0m     process_joint(child)\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'multiply' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "filename = \"cxk\"\n",
    "process_video(f\"{filename}.mp4\", f\"{filename}.bvh\", 0.5, 2, True)\n",
    "# process_video(args.video, args.output, args.confidence, args.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b71744f-442f-4b39-9170-06aff830ed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nlarion/Desktop/nlp_html_ads/myVideoToBvh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlarion/Desktop/nlp_html_ads/nlp_html_env/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd myVideoToBvh/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90182d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
