{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87e91e6-0760-4e3e-99c0-e1c96cc38de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 13:22:56.977065: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740604976.995605   32783 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740604977.001471   32783 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-26 13:22:57.022299: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import argparse\n",
    "from typing import List, Dict, Tuple\n",
    "import os\n",
    "\n",
    "class MediaPipeToBVH:\n",
    "    def __init__(self, fps: int = 30, scale: float = 100.0):\n",
    "        self.mp_pose = mp.solutions.pose\n",
    "        self.fps = fps\n",
    "        self.scale = scale\n",
    "        \n",
    "        # Define the BVH skeleton hierarchy\n",
    "        self.joint_hierarchy = {\n",
    "            \"Hips\": [\"Spine\", \"LeftUpLeg\", \"RightUpLeg\"],\n",
    "            \"Spine\": [\"Spine1\"],\n",
    "            \"Spine1\": [\"Neck\", \"LeftShoulder\", \"RightShoulder\"],\n",
    "            \"Neck\": [\"Head\"],\n",
    "            \"Head\": [\"End_Head\"],\n",
    "            \"LeftShoulder\": [\"LeftArm\"],\n",
    "            \"LeftArm\": [\"LeftForeArm\"],\n",
    "            \"LeftForeArm\": [\"LeftHand\"],\n",
    "            \"LeftHand\": [\"End_LeftHand\"],\n",
    "            \"RightShoulder\": [\"RightArm\"],\n",
    "            \"RightArm\": [\"RightForeArm\"],\n",
    "            \"RightForeArm\": [\"RightHand\"],\n",
    "            \"RightHand\": [\"End_RightHand\"],\n",
    "            \"LeftUpLeg\": [\"LeftLeg\"],\n",
    "            \"LeftLeg\": [\"LeftFoot\"],\n",
    "            \"LeftFoot\": [\"End_LeftFoot\"],\n",
    "            \"RightUpLeg\": [\"RightLeg\"],\n",
    "            \"RightLeg\": [\"RightFoot\"],\n",
    "            \"RightFoot\": [\"End_RightFoot\"]\n",
    "        }\n",
    "        \n",
    "        # MediaPipe landmark indices for joints\n",
    "        self.landmark_to_joint = {\n",
    "            \"Hips\": [23, 24],\n",
    "            \"Spine\": [11, 12, 23, 24],\n",
    "            \"Spine1\": [11, 12],\n",
    "            \"Neck\": [11, 12],\n",
    "            \"Head\": [0],\n",
    "            \"LeftShoulder\": [11],\n",
    "            \"LeftArm\": [13],\n",
    "            \"LeftForeArm\": [15],\n",
    "            \"LeftHand\": [17, 19, 21],\n",
    "            \"RightShoulder\": [12],\n",
    "            \"RightArm\": [14],\n",
    "            \"RightForeArm\": [16],\n",
    "            \"RightHand\": [18, 20, 22],\n",
    "            \"LeftUpLeg\": [23],\n",
    "            \"LeftLeg\": [25],\n",
    "            \"LeftFoot\": [27, 31],\n",
    "            \"RightUpLeg\": [24],\n",
    "            \"RightLeg\": [26],\n",
    "            \"RightFoot\": [28, 32]\n",
    "        }\n",
    "        \n",
    "        # End site offsets (fixed offsets for end joints)\n",
    "        self.end_site_offsets = {\n",
    "            \"End_Head\": (0, 20, 0),\n",
    "            \"End_LeftHand\": (0, -10, 0),\n",
    "            \"End_RightHand\": (0, -10, 0),\n",
    "            \"End_LeftFoot\": (0, -5, 10),\n",
    "            \"End_RightFoot\": (0, -5, 10)\n",
    "        }\n",
    "        \n",
    "        # Initial poses\n",
    "        self.pose = self.mp_pose.Pose(\n",
    "            static_image_mode=False,\n",
    "            model_complexity=2,\n",
    "            smooth_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "    def process_video(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Could not open video file {video_path}\")\n",
    "        \n",
    "        frames = []\n",
    "        frame_count = 0\n",
    "        \n",
    "        while True:\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "            \n",
    "            # Skip frames for efficiency if needed\n",
    "            frame_count += 1\n",
    "            if frame_count % 2 != 0:  # Process every 2nd frame\n",
    "                continue\n",
    "                \n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = self.pose.process(image_rgb)\n",
    "            \n",
    "            if results.pose_world_landmarks:\n",
    "                landmarks_dict = {}\n",
    "                for i, landmark in enumerate(results.pose_world_landmarks.landmark):\n",
    "                    landmarks_dict[i] = {\n",
    "                        'x': landmark.x,\n",
    "                        'y': landmark.y,\n",
    "                        'z': landmark.z,\n",
    "                        'visibility': landmark.visibility\n",
    "                    }\n",
    "                frames.append(landmarks_dict)\n",
    "                \n",
    "                if len(frames) % 10 == 0:\n",
    "                    print(f\"Processed {len(frames)} frames...\")\n",
    "            else:\n",
    "                print(f\"No pose detected in frame {frame_count}\")\n",
    "                if frames:\n",
    "                    frames.append(frames[-1])\n",
    "        \n",
    "        cap.release()\n",
    "        print(f\"Extracted pose data from {len(frames)} frames\")\n",
    "        return frames\n",
    "\n",
    "    def get_joint_positions(self, frames):\n",
    "        joint_positions = []\n",
    "        \n",
    "        for frame in frames:\n",
    "            positions = {}\n",
    "            \n",
    "            for joint_name, indices in self.landmark_to_joint.items():\n",
    "                pos = [0, 0, 0]\n",
    "                weight = 1.0 / len(indices)\n",
    "                \n",
    "                for idx in indices:\n",
    "                    pos[0] += frame[idx]['x'] * weight\n",
    "                    pos[1] += frame[idx]['y'] * weight\n",
    "                    pos[2] += frame[idx]['z'] * weight\n",
    "                \n",
    "                # Scale and convert coordinates\n",
    "                # MediaPipe: Y is up, X is right, Z is toward camera\n",
    "                # Standard BVH: Y is up, X is right, Z is forward (away from camera)\n",
    "                positions[joint_name] = {\n",
    "                    'x': pos[0] * self.scale,\n",
    "                    'y': pos[1] * self.scale,\n",
    "                    'z': -pos[2] * self.scale  # Negate Z to flip direction\n",
    "                }\n",
    "            \n",
    "            joint_positions.append(positions)\n",
    "        \n",
    "        return joint_positions\n",
    "\n",
    "    def smooth_positions(self, positions, window=5):\n",
    "        if len(positions) <= 1:\n",
    "            return positions\n",
    "            \n",
    "        smoothed = []\n",
    "        joint_names = positions[0].keys()\n",
    "        \n",
    "        # First frame remains the same\n",
    "        smoothed.append(positions[0])\n",
    "        \n",
    "        # Apply moving average to middle frames\n",
    "        for i in range(1, len(positions) - 1):\n",
    "            smooth_frame = {}\n",
    "            \n",
    "            for joint in joint_names:\n",
    "                start = max(0, i - window // 2)\n",
    "                end = min(len(positions), i + window // 2 + 1)\n",
    "                \n",
    "                x_sum = y_sum = z_sum = 0\n",
    "                count = 0\n",
    "                \n",
    "                for j in range(start, end):\n",
    "                    if joint in positions[j]:\n",
    "                        x_sum += positions[j][joint]['x']\n",
    "                        y_sum += positions[j][joint]['y']\n",
    "                        z_sum += positions[j][joint]['z']\n",
    "                        count += 1\n",
    "                \n",
    "                if count > 0:\n",
    "                    smooth_frame[joint] = {\n",
    "                        'x': x_sum / count,\n",
    "                        'y': y_sum / count,\n",
    "                        'z': z_sum / count\n",
    "                    }\n",
    "                else:\n",
    "                    smooth_frame[joint] = positions[i][joint]\n",
    "            \n",
    "            smoothed.append(smooth_frame)\n",
    "        \n",
    "        # Last frame remains the same\n",
    "        if len(positions) > 1:\n",
    "            smoothed.append(positions[-1])\n",
    "        \n",
    "        return smoothed\n",
    "\n",
    "    def calculate_offsets(self, reference_frame):\n",
    "        offsets = {}\n",
    "        \n",
    "        for joint, children in self.joint_hierarchy.items():\n",
    "            if joint not in reference_frame:\n",
    "                continue\n",
    "                \n",
    "            parent_pos = reference_frame[joint]\n",
    "            \n",
    "            for child in children:\n",
    "                if child.startswith(\"End_\"):\n",
    "                    # Use predefined end site offset\n",
    "                    offsets[child] = self.end_site_offsets[child]\n",
    "                elif child in reference_frame:\n",
    "                    child_pos = reference_frame[child]\n",
    "                    offsets[child] = (\n",
    "                        child_pos['x'] - parent_pos['x'],\n",
    "                        child_pos['y'] - parent_pos['y'],\n",
    "                        child_pos['z'] - parent_pos['z']\n",
    "                    )\n",
    "        \n",
    "        return offsets\n",
    "\n",
    "    def write_bvh(self, positions, output_path):\n",
    "        # Use the first good frame for the skeleton\n",
    "        offsets = self.calculate_offsets(positions[0])\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            # Write header\n",
    "            f.write(\"HIERARCHY\\n\")\n",
    "            f.write(\"ROOT Hips\\n\")\n",
    "            f.write(\"{\\n\")\n",
    "            f.write(\"\\tOFFSET 0.00 0.00 0.00\\n\")\n",
    "            f.write(\"\\tCHANNELS 6 Xposition Yposition Zposition Xrotation Yrotation Zrotation\\n\")\n",
    "            \n",
    "            # Write joint hierarchy\n",
    "            self._write_joint_hierarchy(f, \"Hips\", offsets, 1)\n",
    "            \n",
    "            # End hierarchy section\n",
    "            f.write(\"}\\n\")\n",
    "            \n",
    "            # Write motion section\n",
    "            f.write(\"MOTION\\n\")\n",
    "            f.write(f\"Frames: {len(positions)}\\n\")\n",
    "            f.write(f\"Frame Time: {1.0/self.fps:.6f}\\n\")\n",
    "            \n",
    "            # Write each frame\n",
    "            for i, frame in enumerate(positions):\n",
    "                line = []\n",
    "                \n",
    "                # Root position\n",
    "                hips = frame[\"Hips\"]\n",
    "                line.extend([hips['x'], hips['y'], hips['z']])\n",
    "                \n",
    "                # Add all rotations (simplified - all 0 for this example)\n",
    "                for joint in self._get_joint_list(\"Hips\"):\n",
    "                    if not joint.startswith(\"End_\"):\n",
    "                        # For simplicity, just use 0 rotations\n",
    "                        # In a real implementation, calculate proper joint rotations\n",
    "                        line.extend([0.0, 0.0, 0.0])\n",
    "                \n",
    "                f.write(\" \".join(f\"{val:.6f}\" for val in line) + \"\\n\")\n",
    "        \n",
    "        print(f\"BVH file written to {output_path}\")\n",
    "\n",
    "    def _write_joint_hierarchy(self, file, joint_name, offsets, indent_level):\n",
    "        indent = \"\\t\" * indent_level\n",
    "        \n",
    "        for child in self.joint_hierarchy.get(joint_name, []):\n",
    "            if child.startswith(\"End_\"):\n",
    "                # Write end site\n",
    "                file.write(f\"{indent}End Site\\n\")\n",
    "                file.write(f\"{indent}{{\\n\")\n",
    "                \n",
    "                offset = offsets.get(child, (0, 0, 0))\n",
    "                file.write(f\"{indent}\\tOFFSET {offset[0]:.6f} {offset[1]:.6f} {offset[2]:.6f}\\n\")\n",
    "                \n",
    "                file.write(f\"{indent}}}\\n\")\n",
    "            else:\n",
    "                # Write child joint\n",
    "                file.write(f\"{indent}JOINT {child}\\n\")\n",
    "                file.write(f\"{indent}{{\\n\")\n",
    "                \n",
    "                offset = offsets.get(child, (0, 0, 0))\n",
    "                file.write(f\"{indent}\\tOFFSET {offset[0]:.6f} {offset[1]:.6f} {offset[2]:.6f}\\n\")\n",
    "                \n",
    "                # All non-root joints have rotation only\n",
    "                file.write(f\"{indent}\\tCHANNELS 3 Xrotation Yrotation Zrotation\\n\")\n",
    "                \n",
    "                # Write child's children\n",
    "                self._write_joint_hierarchy(file, child, offsets, indent_level + 1)\n",
    "                \n",
    "                file.write(f\"{indent}}}\\n\")\n",
    "\n",
    "    def _get_joint_list(self, start_joint):\n",
    "        \"\"\"Get a flat list of all joints in hierarchy order\"\"\"\n",
    "        joints = [start_joint]\n",
    "        \n",
    "        for child in self.joint_hierarchy.get(start_joint, []):\n",
    "            if not child.startswith(\"End_\"):\n",
    "                joints.extend(self._get_joint_list(child))\n",
    "        \n",
    "        return joints\n",
    "\n",
    "    def convert_video_to_bvh(self, video_path, output_path):\n",
    "        print(f\"Processing video: {video_path}\")\n",
    "        frames = self.process_video(video_path)\n",
    "        \n",
    "        if not frames:\n",
    "            print(\"No pose data detected. Check your video.\")\n",
    "            return False\n",
    "        \n",
    "        print(\"Calculating joint positions...\")\n",
    "        positions = self.get_joint_positions(frames)\n",
    "        \n",
    "        print(\"Smoothing motion...\")\n",
    "        smoothed = self.smooth_positions(positions)\n",
    "        \n",
    "        print(f\"Writing BVH file to: {output_path}\")\n",
    "        self.write_bvh(smoothed, output_path)\n",
    "        \n",
    "        return True\n",
    "\n",
    "# def main():\n",
    "#     parser = argparse.ArgumentParser(description='Convert video to BVH using MediaPipe.')\n",
    "#     parser.add_argument('--input', type=str, required=True, help='Input video file')\n",
    "#     parser.add_argument('--output', type=str, help='Output BVH file')\n",
    "#     parser.add_argument('--fps', type=int, default=30, help='Frames per second for BVH')\n",
    "#     parser.add_argument('--scale', type=float, default=100.0, help='Scale factor for the skeleton')\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     if not args.output:\n",
    "#         base_name = os.path.splitext(os.path.basename(args.input))[0]\n",
    "#         args.output = f\"{base_name}.bvh\"\n",
    "    \n",
    "#     converter = MediaPipeToBVH(fps=args.fps, scale=args.scale)\n",
    "#     converter.convert_video_to_bvh(args.input, args.output)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9770f0eb-f73e-439a-883e-5bbc7d3fd852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740604980.513083   32783 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1740604980.515587   34100 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1740604980.606802   34079 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740604980.714121   34087 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: fight1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1740604980.828017   34087 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 frames...\n",
      "Processed 20 frames...\n",
      "Processed 30 frames...\n",
      "Processed 40 frames...\n",
      "Extracted pose data from 45 frames\n",
      "Calculating joint positions...\n",
      "Smoothing motion...\n",
      "Writing BVH file to: fight1.bvh\n",
      "BVH file written to fight1.bvh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"fight1\"\n",
    "converter = MediaPipeToBVH(fps=30, scale=100.0)\n",
    "converter.convert_video_to_bvh(f\"{filename}.mp4\", f\"{filename}.bvh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522a83f-a88c-450e-8598-2db1f13c99ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
