{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2f4782-3cb0-45ae-9d8c-6b78620fd4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 16:31:59.551626: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740616319.567172   23736 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740616319.572264   23736 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-26 16:31:59.588623: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "# MediaPipe setup\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# BVH Joint Structure\n",
    "class Joint:\n",
    "    def __init__(self, name, parent=None):\n",
    "        self.name = name\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.offset = np.zeros(3)\n",
    "        self.channels = []\n",
    "        self.rotation_order = 'ZXY'  # Default rotation order\n",
    "        self.positions = []\n",
    "        self.rotations = []\n",
    "        \n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "        \n",
    "def create_skeleton():\n",
    "    \"\"\"Create a skeleton structure that matches MediaPipe's pose landmarks.\"\"\"\n",
    "    # Root joint\n",
    "    hips = Joint(\"Hips\")\n",
    "    \n",
    "    # Spine\n",
    "    spine = Joint(\"Spine\", hips)\n",
    "    hips.add_child(spine)\n",
    "    \n",
    "    chest = Joint(\"Chest\", spine)\n",
    "    spine.add_child(chest)\n",
    "    \n",
    "    neck = Joint(\"Neck\", chest)\n",
    "    chest.add_child(neck)\n",
    "    \n",
    "    head = Joint(\"Head\", neck)\n",
    "    neck.add_child(head)\n",
    "    \n",
    "    # Left arm\n",
    "    left_shoulder = Joint(\"LeftShoulder\", chest)\n",
    "    chest.add_child(left_shoulder)\n",
    "    \n",
    "    left_arm = Joint(\"LeftArm\", left_shoulder)\n",
    "    left_shoulder.add_child(left_arm)\n",
    "    \n",
    "    left_forearm = Joint(\"LeftForeArm\", left_arm)\n",
    "    left_arm.add_child(left_forearm)\n",
    "    \n",
    "    left_hand = Joint(\"LeftHand\", left_forearm)\n",
    "    left_forearm.add_child(left_hand)\n",
    "    \n",
    "    # Right arm\n",
    "    right_shoulder = Joint(\"RightShoulder\", chest)\n",
    "    chest.add_child(right_shoulder)\n",
    "    \n",
    "    right_arm = Joint(\"RightArm\", right_shoulder)\n",
    "    right_shoulder.add_child(right_arm)\n",
    "    \n",
    "    right_forearm = Joint(\"RightForeArm\", right_arm)\n",
    "    right_arm.add_child(right_forearm)\n",
    "    \n",
    "    right_hand = Joint(\"RightHand\", right_forearm)\n",
    "    right_forearm.add_child(right_hand)\n",
    "    \n",
    "    # Left leg\n",
    "    left_up_leg = Joint(\"LeftUpLeg\", hips)\n",
    "    hips.add_child(left_up_leg)\n",
    "    \n",
    "    left_leg = Joint(\"LeftLeg\", left_up_leg)\n",
    "    left_up_leg.add_child(left_leg)\n",
    "    \n",
    "    left_foot = Joint(\"LeftFoot\", left_leg)\n",
    "    left_leg.add_child(left_foot)\n",
    "    \n",
    "    left_toe = Joint(\"LeftToeBase\", left_foot)\n",
    "    left_foot.add_child(left_toe)\n",
    "    \n",
    "    # Right leg\n",
    "    right_up_leg = Joint(\"RightUpLeg\", hips)\n",
    "    hips.add_child(right_up_leg)\n",
    "    \n",
    "    right_leg = Joint(\"RightLeg\", right_up_leg)\n",
    "    right_up_leg.add_child(right_leg)\n",
    "    \n",
    "    right_foot = Joint(\"RightFoot\", right_leg)\n",
    "    right_leg.add_child(right_foot)\n",
    "    \n",
    "    right_toe = Joint(\"RightToeBase\", right_foot)\n",
    "    right_foot.add_child(right_toe)\n",
    "    \n",
    "    return hips\n",
    "\n",
    "def get_joint_mapping():\n",
    "    \"\"\"Map MediaPipe landmarks to skeleton joints.\"\"\"\n",
    "    # MediaPipe pose landmarks: https://developers.google.com/mediapipe/solutions/vision/pose_landmarker\n",
    "    return {\n",
    "        \"Hips\": [mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "        \"Spine\": [mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        \"Chest\": [mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        \"Neck\": [mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.NOSE],\n",
    "        \"Head\": [mp_pose.PoseLandmark.NOSE],\n",
    "        \"LeftShoulder\": [mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "        \"LeftArm\": [mp_pose.PoseLandmark.LEFT_ELBOW],\n",
    "        \"LeftForeArm\": [mp_pose.PoseLandmark.LEFT_WRIST],\n",
    "        \"LeftHand\": [mp_pose.PoseLandmark.LEFT_PINKY, mp_pose.PoseLandmark.LEFT_INDEX, mp_pose.PoseLandmark.LEFT_THUMB],\n",
    "        \"RightShoulder\": [mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "        \"RightArm\": [mp_pose.PoseLandmark.RIGHT_ELBOW],\n",
    "        \"RightForeArm\": [mp_pose.PoseLandmark.RIGHT_WRIST],\n",
    "        \"RightHand\": [mp_pose.PoseLandmark.RIGHT_PINKY, mp_pose.PoseLandmark.RIGHT_INDEX, mp_pose.PoseLandmark.RIGHT_THUMB],\n",
    "        \"LeftUpLeg\": [mp_pose.PoseLandmark.LEFT_HIP],\n",
    "        \"LeftLeg\": [mp_pose.PoseLandmark.LEFT_KNEE],\n",
    "        \"LeftFoot\": [mp_pose.PoseLandmark.LEFT_ANKLE],\n",
    "        \"LeftToeBase\": [mp_pose.PoseLandmark.LEFT_FOOT_INDEX],\n",
    "        \"RightUpLeg\": [mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "        \"RightLeg\": [mp_pose.PoseLandmark.RIGHT_KNEE],\n",
    "        \"RightFoot\": [mp_pose.PoseLandmark.RIGHT_ANKLE],\n",
    "        \"RightToeBase\": [mp_pose.PoseLandmark.RIGHT_FOOT_INDEX]\n",
    "    }\n",
    "\n",
    "def calculate_joint_offsets(joint, landmarks, joint_mapping, frame_idx=0):\n",
    "    \"\"\"Calculate the offset for a joint based on MediaPipe landmarks.\"\"\"\n",
    "    if joint.name in joint_mapping:\n",
    "        indices = joint_mapping[joint.name]\n",
    "        position = np.zeros(3)\n",
    "        \n",
    "        for idx in indices:\n",
    "            # Use the first frame for skeletal structure calculation\n",
    "            lm = landmarks[frame_idx][idx]\n",
    "            position += np.array([lm.x, lm.y, lm.z])\n",
    "        \n",
    "        if len(indices) > 0:\n",
    "            position /= len(indices)  # Average position\n",
    "        \n",
    "        if joint.parent:\n",
    "            parent_position = np.zeros(3)\n",
    "            parent_indices = joint_mapping[joint.parent.name]\n",
    "            for idx in parent_indices:\n",
    "                lm = landmarks[frame_idx][idx]\n",
    "                parent_position += np.array([lm.x, lm.y, lm.z])\n",
    "            \n",
    "            if len(parent_indices) > 0:\n",
    "                parent_position /= len(parent_indices)\n",
    "                \n",
    "            # Calculate offset from parent to this joint\n",
    "            offset = position - parent_position\n",
    "            \n",
    "            # Scale offset to make the skeleton more realistic\n",
    "            # MediaPipe uses a normalized coordinate system, so we scale up\n",
    "            joint.offset = offset * 100  # Scale factor can be adjusted\n",
    "        else:\n",
    "            # Root joint, offset from origin\n",
    "            joint.offset = position * 100\n",
    "    \n",
    "    for child in joint.children:\n",
    "        calculate_joint_offsets(child, landmarks, joint_mapping, frame_idx)\n",
    "\n",
    "def quaternion_to_euler(q, order='ZXY'):\n",
    "    \"\"\"Convert quaternion to Euler angles based on specified order.\"\"\"\n",
    "    # q = [w, x, y, z]\n",
    "    w, x, y, z = q\n",
    "    \n",
    "    if order == 'ZXY':\n",
    "        # ZXY rotation order (common in character animation)\n",
    "        sinx = 2.0 * (w * x - y * z)\n",
    "        cosx = 1.0 - 2.0 * (x * x + y * y)\n",
    "        angle_x = math.atan2(sinx, cosx)\n",
    "        \n",
    "        siny = 2.0 * (w * y + x * z)\n",
    "        angle_y = math.asin(siny if siny <= 1.0 else 1.0)\n",
    "        \n",
    "        sinz = 2.0 * (w * z + x * y)\n",
    "        cosz = 1.0 - 2.0 * (y * y + z * z)\n",
    "        angle_z = math.atan2(sinz, cosz)\n",
    "        \n",
    "        return np.array([math.degrees(angle_x), math.degrees(angle_y), math.degrees(angle_z)])\n",
    "    \n",
    "    else:\n",
    "        # Default to XYZ if order not recognized\n",
    "        angles = np.zeros(3)\n",
    "        # More rotation order calculations would go here\n",
    "        return angles\n",
    "\n",
    "def calculate_rotation(joint, landmarks, joint_mapping, frame_idx):\n",
    "    \"\"\"Calculate rotation for a joint based on MediaPipe landmarks.\"\"\"\n",
    "    # This is a simplified approach - in a real system you'd use more robust methods\n",
    "    # to calculate proper bone rotations from the landmark positions\n",
    "    \n",
    "    if joint.name in joint_mapping and len(joint.children) > 0:\n",
    "        # Get joint position\n",
    "        indices = joint_mapping[joint.name]\n",
    "        position = np.zeros(3)\n",
    "        for idx in indices:\n",
    "            lm = landmarks[frame_idx][idx]\n",
    "            position += np.array([lm.x, lm.y, lm.z])\n",
    "        \n",
    "        if len(indices) > 0:\n",
    "            position /= len(indices)\n",
    "        \n",
    "        # Get child position (using first child for simplicity)\n",
    "        child_indices = joint_mapping[joint.children[0].name]\n",
    "        child_position = np.zeros(3)\n",
    "        for idx in child_indices:\n",
    "            lm = landmarks[frame_idx][idx]\n",
    "            child_position += np.array([lm.x, lm.y, lm.z])\n",
    "        \n",
    "        if len(child_indices) > 0:\n",
    "            child_position /= len(child_indices)\n",
    "        \n",
    "        # Calculate direction vector\n",
    "        direction = child_position - position\n",
    "        if np.linalg.norm(direction) > 0:\n",
    "            direction = direction / np.linalg.norm(direction)\n",
    "        \n",
    "        # Calculate rotation to align with direction\n",
    "        # This is a simplified approach using quaternions\n",
    "        # Default forward axis is usually (0, 0, 1) in most systems\n",
    "        forward = np.array([0, 0, 1])\n",
    "        \n",
    "        # Calculate rotation axis and angle\n",
    "        axis = np.cross(forward, direction)\n",
    "        if np.linalg.norm(axis) > 0:\n",
    "            axis = axis / np.linalg.norm(axis)\n",
    "        \n",
    "        dot = np.dot(forward, direction)\n",
    "        angle = math.acos(np.clip(dot, -1.0, 1.0))\n",
    "        \n",
    "        # Convert to quaternion\n",
    "        sin_half = math.sin(angle/2)\n",
    "        qw = math.cos(angle/2)\n",
    "        qx = axis[0] * sin_half\n",
    "        qy = axis[1] * sin_half\n",
    "        qz = axis[2] * sin_half\n",
    "        \n",
    "        # Convert quaternion to Euler angles\n",
    "        euler = quaternion_to_euler([qw, qx, qy, qz], joint.rotation_order)\n",
    "        return euler\n",
    "    \n",
    "    return np.zeros(3)  # Default rotation\n",
    "\n",
    "def process_frames(landmarks, joint, joint_mapping):\n",
    "    \"\"\"Process all frames and calculate positions and rotations for each joint.\"\"\"\n",
    "    num_frames = len(landmarks)\n",
    "    \n",
    "    for frame_idx in range(num_frames):\n",
    "        rotation = calculate_rotation(joint, landmarks, joint_mapping, frame_idx)\n",
    "        joint.rotations.append(rotation)\n",
    "        \n",
    "        # Process children\n",
    "        for child in joint.children:\n",
    "            process_frames(landmarks, child, joint_mapping)\n",
    "\n",
    "def write_bvh_file(root_joint, frame_time, output_file):\n",
    "    \"\"\"Write the BVH file with motion data.\"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Write header\n",
    "        f.write(\"HIERARCHY\\n\")\n",
    "        \n",
    "        # Write joint hierarchy recursively\n",
    "        write_joint_hierarchy(f, root_joint, 0)\n",
    "        \n",
    "        # Write motion data\n",
    "        f.write(\"MOTION\\n\")\n",
    "        f.write(f\"Frames: {len(root_joint.rotations)}\\n\")\n",
    "        f.write(f\"Frame Time: {frame_time:.6f}\\n\")\n",
    "        \n",
    "        # Write frame data\n",
    "        for frame_idx in range(len(root_joint.rotations)):\n",
    "            frame_data = []\n",
    "            collect_frame_data(root_joint, frame_idx, frame_data)\n",
    "            f.write(\" \".join([f\"{val:.6f}\" for val in frame_data]) + \"\\n\")\n",
    "\n",
    "def write_joint_hierarchy(f, joint, indent_level):\n",
    "    \"\"\"Write the joint hierarchy recursively.\"\"\"\n",
    "    indent = \"  \" * indent_level\n",
    "    \n",
    "    if joint.parent is None:\n",
    "        # Root joint\n",
    "        f.write(f\"{indent}ROOT {joint.name}\\n\")\n",
    "    else:\n",
    "        # Child joint\n",
    "        f.write(f\"{indent}JOINT {joint.name}\\n\")\n",
    "    \n",
    "    f.write(f\"{indent}\" + \"{\\n\")\n",
    "    \n",
    "    # Write offset\n",
    "    f.write(f\"{indent}  OFFSET {joint.offset[0]:.6f} {joint.offset[1]:.6f} {joint.offset[2]:.6f}\\n\")\n",
    "    \n",
    "    # Write channels\n",
    "    if joint.parent is None:\n",
    "        # Root has 6 channels: position and rotation\n",
    "        f.write(f\"{indent}  CHANNELS 6 Xposition Yposition Zposition {joint.rotation_order[0]}rotation {joint.rotation_order[1]}rotation {joint.rotation_order[2]}rotation\\n\")\n",
    "        joint.channels = ['Xposition', 'Yposition', 'Zposition', f'{joint.rotation_order[0]}rotation', f'{joint.rotation_order[1]}rotation', f'{joint.rotation_order[2]}rotation']\n",
    "    else:\n",
    "        # Other joints have 3 channels: rotation only\n",
    "        f.write(f\"{indent}  CHANNELS 3 {joint.rotation_order[0]}rotation {joint.rotation_order[1]}rotation {joint.rotation_order[2]}rotation\\n\")\n",
    "        joint.channels = [f'{joint.rotation_order[0]}rotation', f'{joint.rotation_order[1]}rotation', f'{joint.rotation_order[2]}rotation']\n",
    "    \n",
    "    # Process children\n",
    "    for child in joint.children:\n",
    "        write_joint_hierarchy(f, child, indent_level + 1)\n",
    "    \n",
    "    # If no children, write end site\n",
    "    if not joint.children:\n",
    "        f.write(f\"{indent}  End Site\\n\")\n",
    "        f.write(f\"{indent}  \" + \"{\\n\")\n",
    "        f.write(f\"{indent}    OFFSET 0.0 0.0 0.0\\n\")\n",
    "        f.write(f\"{indent}  \" + \"}\\n\")\n",
    "    \n",
    "    f.write(f\"{indent}\" + \"}\\n\")\n",
    "\n",
    "def collect_frame_data(joint, frame_idx, frame_data):\n",
    "    \"\"\"Collect frame data for a specific frame.\"\"\"\n",
    "    # Add root position if this is the root joint\n",
    "    if joint.parent is None:\n",
    "        # For simplicity, we're using fixed root position here\n",
    "        # In a real implementation, you'd track the root movement from the video\n",
    "        frame_data.extend([0.0, 0.0, 0.0])  # Root position\n",
    "    \n",
    "    # Add rotation\n",
    "    if frame_idx < len(joint.rotations):\n",
    "        frame_data.extend(joint.rotations[frame_idx])\n",
    "    else:\n",
    "        # If we don't have rotation data for this frame, use zeros\n",
    "        frame_data.extend([0.0, 0.0, 0.0])\n",
    "    \n",
    "    # Process children\n",
    "    for child in joint.children:\n",
    "        collect_frame_data(child, frame_idx, frame_data)\n",
    "\n",
    "def process_video(video_path, output_bvh, confidence_threshold=0.5, sample_rate=1):\n",
    "    \"\"\"Process video and create BVH file.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate frame time based on original FPS and sampling rate\n",
    "    frame_time = 1.0 / (fps / sample_rate)\n",
    "    \n",
    "    # Create pose detector\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=2,  # Use most accurate model\n",
    "        enable_segmentation=False,\n",
    "        min_detection_confidence=confidence_threshold\n",
    "    ) as pose:\n",
    "        \n",
    "        # Process frames\n",
    "        all_landmarks = []\n",
    "        frame_idx = 0\n",
    "        \n",
    "        with tqdm(total=frame_count) as pbar:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Process only every sample_rate frames\n",
    "                if frame_idx % sample_rate == 0:\n",
    "                    # Convert BGR to RGB\n",
    "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    # Process the frame\n",
    "                    results = pose.process(frame_rgb)\n",
    "                    \n",
    "                    if results.pose_landmarks:\n",
    "                        # Store landmarks\n",
    "                        all_landmarks.append(results.pose_world_landmarks.landmark)\n",
    "                    else:\n",
    "                        # If no landmarks detected, use the previous frame's landmarks or zeros\n",
    "                        if all_landmarks:\n",
    "                            all_landmarks.append(all_landmarks[-1])\n",
    "                        else:\n",
    "                            # Create empty landmarks\n",
    "                            empty_landmarks = [mp_pose.PoseLandmark(x=0, y=0, z=0) for _ in range(33)]\n",
    "                            all_landmarks.append(empty_landmarks)\n",
    "                \n",
    "                frame_idx += 1\n",
    "                pbar.update(1)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        if not all_landmarks:\n",
    "            print(\"No pose landmarks detected in the video.\")\n",
    "            return\n",
    "        \n",
    "        # Create skeleton structure\n",
    "        skeleton_root = create_skeleton()\n",
    "        joint_mapping = get_joint_mapping()\n",
    "        \n",
    "        # Calculate joint offsets based on the first frame\n",
    "        calculate_joint_offsets(skeleton_root, all_landmarks, joint_mapping)\n",
    "        \n",
    "        # Process all frames to calculate rotations\n",
    "        process_frames(all_landmarks, skeleton_root, joint_mapping)\n",
    "        \n",
    "        # Write BVH file\n",
    "        write_bvh_file(skeleton_root, frame_time, output_bvh)\n",
    "        \n",
    "        print(f\"BVH file created successfully: {output_bvh}\")\n",
    "\n",
    "# def main():\n",
    "#     parser = argparse.ArgumentParser(description=\"Convert video to BVH using MediaPipe\")\n",
    "#     parser.add_argument(\"--video\", required=True, help=\"Path to input video file\")\n",
    "#     parser.add_argument(\"--output\", required=True, help=\"Path to output BVH file\")\n",
    "#     parser.add_argument(\"--confidence\", type=float, default=0.5, help=\"Confidence threshold for pose detection\")\n",
    "#     parser.add_argument(\"--sample-rate\", type=int, default=2, help=\"Process every Nth frame\")\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     process_video(args.video, args.output, args.confidence, args.sample_rate)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29356d09-f10b-486c-b5b3-3ce5fb123b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740616684.558817   23736 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1740616684.559823   24818 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1740616684.629976   24806 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740616684.725581   24807 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "\n",
      "00%|█████████████████████████████████████████| 481/481 [00:22<00:00, 21.64it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdance6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.bvh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# process_video(args.video, args.output, args.confidence, args.sample_rate)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 403\u001b[0m, in \u001b[0;36mprocess_video\u001b[0;34m(video_path, output_bvh, confidence_threshold, sample_rate)\u001b[0m\n\u001b[1;32m    400\u001b[0m calculate_joint_offsets(skeleton_root, all_landmarks, joint_mapping)\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# Process all frames to calculate rotations\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m \u001b[43mprocess_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_landmarks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskeleton_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# Write BVH file\u001b[39;00m\n\u001b[1;32m    406\u001b[0m write_bvh_file(skeleton_root, frame_time, output_bvh)\n",
      "Cell \u001b[0;32mIn[1], line 257\u001b[0m, in \u001b[0;36mprocess_frames\u001b[0;34m(landmarks, joint, joint_mapping)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Process children\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m joint\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[0;32m--> 257\u001b[0m     \u001b[43mprocess_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlandmarks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint_mapping\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 257\u001b[0m, in \u001b[0;36mprocess_frames\u001b[0;34m(landmarks, joint, joint_mapping)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Process children\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m joint\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[0;32m--> 257\u001b[0m     \u001b[43mprocess_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlandmarks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint_mapping\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: process_frames at line 257 (3 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[1], line 257\u001b[0m, in \u001b[0;36mprocess_frames\u001b[0;34m(landmarks, joint, joint_mapping)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Process children\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m joint\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[0;32m--> 257\u001b[0m     \u001b[43mprocess_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlandmarks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint_mapping\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 252\u001b[0m, in \u001b[0;36mprocess_frames\u001b[0;34m(landmarks, joint, joint_mapping)\u001b[0m\n\u001b[1;32m    249\u001b[0m num_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(landmarks)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_frames):\n\u001b[0;32m--> 252\u001b[0m     rotation \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_rotation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlandmarks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     joint\u001b[38;5;241m.\u001b[39mrotations\u001b[38;5;241m.\u001b[39mappend(rotation)\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Process children\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 195\u001b[0m, in \u001b[0;36mcalculate_rotation\u001b[0;34m(joint, landmarks, joint_mapping, frame_idx)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculate rotation for a joint based on MediaPipe landmarks.\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# This is a simplified approach - in a real system you'd use more robust methods\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# to calculate proper bone rotations from the landmark positions\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m joint\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m joint_mapping \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# Get joint position\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     indices \u001b[38;5;241m=\u001b[39m joint_mapping[joint\u001b[38;5;241m.\u001b[39mname]\n\u001b[1;32m    198\u001b[0m     position \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filename = \"dance6\"\n",
    "process_video(f\"{filename}.mp4\", f\"{filename}.bvh\", 0.5, 2)\n",
    "# process_video(args.video, args.output, args.confidence, args.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82875695-84b0-4e9b-91df-bb4c3abd4dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
