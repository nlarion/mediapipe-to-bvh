{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a03fdc6-5688-4f80-985c-8903551c22d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 17:16:02.661575: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740532562.678734   36185 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740532562.684707   36185 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-25 17:16:02.702125: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "# BVH writing utilities\n",
    "class BVHJoint:\n",
    "    def __init__(self, name, offset=(0, 0, 0), children=None):\n",
    "        self.name = name\n",
    "        self.offset = offset\n",
    "        self.children = children or []\n",
    "        self.channels = []\n",
    "        self.is_end_site = False\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "        return child\n",
    "\n",
    "class BVHWriter:\n",
    "    def __init__(self, root_joint, frame_time=0.033333):\n",
    "        self.root_joint = root_joint\n",
    "        self.frame_time = frame_time\n",
    "        self.motion_data = []\n",
    "        \n",
    "    def add_frame(self, frame_data):\n",
    "        self.motion_data.append(frame_data)\n",
    "        \n",
    "    def write_to_file(self, file_path):\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(\"HIERARCHY\\n\")\n",
    "            self._write_joint(f, self.root_joint, 0)\n",
    "            \n",
    "            f.write(\"MOTION\\n\")\n",
    "            f.write(f\"Frames: {len(self.motion_data)}\\n\")\n",
    "            f.write(f\"Frame Time: {self.frame_time}\\n\")\n",
    "            \n",
    "            for frame in self.motion_data:\n",
    "                f.write(\" \".join(map(str, frame)) + \"\\n\")\n",
    "                \n",
    "    def _write_joint(self, file, joint, indent_level):\n",
    "        indent = \"  \" * indent_level\n",
    "        \n",
    "        if indent_level == 0:\n",
    "            file.write(f\"{indent}ROOT {joint.name}\\n\")\n",
    "        elif joint.is_end_site:\n",
    "            file.write(f\"{indent}End Site\\n\")\n",
    "        else:\n",
    "            file.write(f\"{indent}JOINT {joint.name}\\n\")\n",
    "            \n",
    "        file.write(f\"{indent}{{\\n\")\n",
    "        file.write(f\"{indent}  OFFSET {joint.offset[0]} {joint.offset[1]} {joint.offset[2]}\\n\")\n",
    "        \n",
    "        if not joint.is_end_site:\n",
    "            if indent_level == 0:\n",
    "                # Root joint typically has 6 channels: position and rotation\n",
    "                file.write(f\"{indent}  CHANNELS 6 Xposition Yposition Zposition Zrotation Xrotation Yrotation\\n\")\n",
    "                joint.channels = [\"Xposition\", \"Yposition\", \"Zposition\", \"Zrotation\", \"Xrotation\", \"Yrotation\"]\n",
    "            else:\n",
    "                # Other joints typically have 3 channels for rotation only\n",
    "                file.write(f\"{indent}  CHANNELS 3 Zrotation Xrotation Yrotation\\n\")\n",
    "                joint.channels = [\"Zrotation\", \"Xrotation\", \"Yrotation\"]\n",
    "        \n",
    "        for child in joint.children:\n",
    "            self._write_joint(file, child, indent_level + 1)\n",
    "            \n",
    "        file.write(f\"{indent}}}\\n\")\n",
    "\n",
    "# MediaPipe pose detection setup\n",
    "def setup_mediapipe():\n",
    "    mp_pose = mp.solutions.pose\n",
    "    return mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=False,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "\n",
    "# Create a simplified skeleton hierarchy for BVH\n",
    "def create_skeleton():\n",
    "    root = BVHJoint(\"Hips\", offset=(0, 0, 0))\n",
    "    \n",
    "    spine = root.add_child(BVHJoint(\"Spine\", offset=(0, 10, 0)))\n",
    "    neck = spine.add_child(BVHJoint(\"Neck\", offset=(0, 15, 0)))\n",
    "    head = neck.add_child(BVHJoint(\"Head\", offset=(0, 5, 0)))\n",
    "    head_end = head.add_child(BVHJoint(\"HeadEnd\", offset=(0, 3, 0)))\n",
    "    head_end.is_end_site = True\n",
    "    \n",
    "    left_shoulder = spine.add_child(BVHJoint(\"LeftShoulder\", offset=(5, 12, 0)))\n",
    "    left_elbow = left_shoulder.add_child(BVHJoint(\"LeftElbow\", offset=(10, 0, 0)))\n",
    "    left_wrist = left_elbow.add_child(BVHJoint(\"LeftWrist\", offset=(8, 0, 0)))\n",
    "    left_hand = left_wrist.add_child(BVHJoint(\"LeftHand\", offset=(4, 0, 0)))\n",
    "    left_hand.is_end_site = True\n",
    "    \n",
    "    right_shoulder = spine.add_child(BVHJoint(\"RightShoulder\", offset=(-5, 12, 0)))\n",
    "    right_elbow = right_shoulder.add_child(BVHJoint(\"RightElbow\", offset=(-10, 0, 0)))\n",
    "    right_wrist = right_elbow.add_child(BVHJoint(\"RightWrist\", offset=(-8, 0, 0)))\n",
    "    right_hand = right_wrist.add_child(BVHJoint(\"RightHand\", offset=(-4, 0, 0)))\n",
    "    right_hand.is_end_site = True\n",
    "    \n",
    "    left_hip = root.add_child(BVHJoint(\"LeftHip\", offset=(3.5, 0, 0)))\n",
    "    left_knee = left_hip.add_child(BVHJoint(\"LeftKnee\", offset=(0, -15, 0)))\n",
    "    left_ankle = left_knee.add_child(BVHJoint(\"LeftAnkle\", offset=(0, -15, 0)))\n",
    "    left_foot = left_ankle.add_child(BVHJoint(\"LeftFoot\", offset=(0, -3, 5)))\n",
    "    left_foot.is_end_site = True\n",
    "    \n",
    "    right_hip = root.add_child(BVHJoint(\"RightHip\", offset=(-3.5, 0, 0)))\n",
    "    right_knee = right_hip.add_child(BVHJoint(\"RightKnee\", offset=(0, -15, 0)))\n",
    "    right_ankle = right_knee.add_child(BVHJoint(\"RightAnkle\", offset=(0, -15, 0)))\n",
    "    right_foot = right_ankle.add_child(BVHJoint(\"RightFoot\", offset=(0, -3, 5)))\n",
    "    right_foot.is_end_site = True\n",
    "    \n",
    "    return root\n",
    "\n",
    "# Extract joint position from MediaPipe landmarks\n",
    "def get_joint_position(landmarks, idx):\n",
    "    landmark = landmarks[idx]\n",
    "    # Scale and transform coordinates\n",
    "    return np.array([\n",
    "        landmark.x * 100,\n",
    "        -landmark.y * 100 + 100, # Convert from top-left to bottom-left origin\n",
    "        landmark.z * 100\n",
    "    ])\n",
    "\n",
    "# Calculate angle between two vectors\n",
    "def angle_between(v1, v2):\n",
    "    v1_u = v1 / np.linalg.norm(v1)\n",
    "    v2_u = v2 / np.linalg.norm(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "# Simple rotation calculation\n",
    "def calculate_joint_rotation(joint_pos, child_pos, ref_vector=None):\n",
    "    if ref_vector is None:\n",
    "        # Default reference vectors\n",
    "        refs = {\n",
    "            \"x\": np.array([1, 0, 0]),\n",
    "            \"y\": np.array([0, 1, 0]),\n",
    "            \"z\": np.array([0, 0, 1])\n",
    "        }\n",
    "    else:\n",
    "        refs = ref_vector\n",
    "    \n",
    "    # Calculate direction vector from joint to child\n",
    "    direction = child_pos - joint_pos\n",
    "    if np.linalg.norm(direction) < 1e-6:\n",
    "        return [0, 0, 0]  # No rotation if points are too close\n",
    "    \n",
    "    direction = direction / np.linalg.norm(direction)\n",
    "    \n",
    "    # Calculate rotation around each axis\n",
    "    # Note: This is a simplified calculation that may not be fully accurate\n",
    "    # for complex rotations, but often works well in practice for visualization\n",
    "    \n",
    "    # Project to planes and calculate angles\n",
    "    xy_proj = np.array([direction[0], direction[1], 0])\n",
    "    if np.linalg.norm(xy_proj) > 1e-6:\n",
    "        xy_proj = xy_proj / np.linalg.norm(xy_proj)\n",
    "        z_rot = np.degrees(angle_between(np.array([1, 0, 0]), xy_proj))\n",
    "        if xy_proj[1] < 0:\n",
    "            z_rot = -z_rot\n",
    "    else:\n",
    "        z_rot = 0\n",
    "    \n",
    "    xz_proj = np.array([direction[0], 0, direction[2]])\n",
    "    if np.linalg.norm(xz_proj) > 1e-6:\n",
    "        xz_proj = xz_proj / np.linalg.norm(xz_proj)\n",
    "        y_rot = np.degrees(angle_between(np.array([1, 0, 0]), xz_proj))\n",
    "        if xz_proj[2] < 0:\n",
    "            y_rot = -y_rot\n",
    "    else:\n",
    "        y_rot = 0\n",
    "    \n",
    "    yz_proj = np.array([0, direction[1], direction[2]])\n",
    "    if np.linalg.norm(yz_proj) > 1e-6:\n",
    "        yz_proj = yz_proj / np.linalg.norm(yz_proj)\n",
    "        x_rot = np.degrees(angle_between(np.array([0, 1, 0]), yz_proj))\n",
    "        if yz_proj[2] < 0:\n",
    "            x_rot = -x_rot\n",
    "    else:\n",
    "        x_rot = 0\n",
    "    \n",
    "    # BVH rotation order is ZXY\n",
    "    return [z_rot, x_rot, y_rot]\n",
    "\n",
    "# Process video and generate BVH\n",
    "def process_video(video_path, output_path, fps_target=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Determine frame sampling to match target FPS\n",
    "    frame_skip = max(1, round(video_fps / fps_target))\n",
    "    frame_time = 1.0 / fps_target\n",
    "    \n",
    "    # Initialize MediaPipe\n",
    "    pose_detector = setup_mediapipe()\n",
    "    \n",
    "    # Create BVH skeleton and writer\n",
    "    root_joint = create_skeleton()\n",
    "    bvh_writer = BVHWriter(root_joint, frame_time=frame_time)\n",
    "    \n",
    "    frame_count = 0\n",
    "    processed_count = 0\n",
    "    \n",
    "    mp_pose = mp.solutions.pose\n",
    "    \n",
    "    # Mapping from MediaPipe landmarks to our skeleton\n",
    "    landmarks_map = {\n",
    "        \"Hips\": [mp_pose.PoseLandmark.LEFT_HIP.value, mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "        \"Spine\": [mp_pose.PoseLandmark.LEFT_SHOULDER.value, mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "        \"Neck\": [mp_pose.PoseLandmark.LEFT_SHOULDER.value, mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "        \"Head\": [mp_pose.PoseLandmark.NOSE.value],\n",
    "        \"LeftShoulder\": [mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "        \"LeftElbow\": [mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "        \"LeftWrist\": [mp_pose.PoseLandmark.LEFT_WRIST.value],\n",
    "        \"RightShoulder\": [mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "        \"RightElbow\": [mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "        \"RightWrist\": [mp_pose.PoseLandmark.RIGHT_WRIST.value],\n",
    "        \"LeftHip\": [mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "        \"LeftKnee\": [mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "        \"LeftAnkle\": [mp_pose.PoseLandmark.LEFT_ANKLE.value],\n",
    "        \"RightHip\": [mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "        \"RightKnee\": [mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "        \"RightAnkle\": [mp_pose.PoseLandmark.RIGHT_ANKLE.value]\n",
    "    }\n",
    "    \n",
    "    # Joint connections for calculating rotations\n",
    "    joint_connections = {\n",
    "        \"Hips\": \"Spine\",\n",
    "        \"Spine\": \"Neck\",\n",
    "        \"Neck\": \"Head\",\n",
    "        \"Head\": None,  # No further connection\n",
    "        \"LeftShoulder\": \"LeftElbow\",\n",
    "        \"LeftElbow\": \"LeftWrist\",\n",
    "        \"LeftWrist\": None,  # End joint\n",
    "        \"RightShoulder\": \"RightElbow\",\n",
    "        \"RightElbow\": \"RightWrist\",\n",
    "        \"RightWrist\": None,  # End joint\n",
    "        \"LeftHip\": \"LeftKnee\",\n",
    "        \"LeftKnee\": \"LeftAnkle\",\n",
    "        \"LeftAnkle\": None,  # End joint\n",
    "        \"RightHip\": \"RightKnee\",\n",
    "        \"RightKnee\": \"RightAnkle\",\n",
    "        \"RightAnkle\": None  # End joint\n",
    "    }\n",
    "    \n",
    "    # For simple rotation smoothing\n",
    "    prev_rotations = {}\n",
    "    \n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    print(f\"Target FPS: {fps_target}, Frame time: {frame_time}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Process only selected frames to match target FPS\n",
    "        if (frame_count - 1) % frame_skip != 0:\n",
    "            continue\n",
    "        \n",
    "        processed_count += 1\n",
    "        \n",
    "        # Convert to RGB for MediaPipe\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect pose\n",
    "        results = pose_detector.process(rgb_frame)\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Extract positions for all landmarks\n",
    "            joint_positions = {}\n",
    "            for joint_name, landmark_indices in landmarks_map.items():\n",
    "                if landmark_indices:\n",
    "                    # For joints that are defined by multiple landmarks (e.g., Hips), take the average\n",
    "                    positions = [get_joint_position(landmarks, idx) for idx in landmark_indices]\n",
    "                    joint_positions[joint_name] = np.mean(positions, axis=0)\n",
    "            \n",
    "            # Generate frame data for BVH\n",
    "            frame_data = []\n",
    "            \n",
    "            # Root position (translation)\n",
    "            if \"Hips\" in joint_positions:\n",
    "                hips_pos = joint_positions[\"Hips\"]\n",
    "                frame_data.extend([hips_pos[0], hips_pos[1], hips_pos[2]])\n",
    "            else:\n",
    "                # Default position if hips not detected\n",
    "                frame_data.extend([0, 0, 0])\n",
    "            \n",
    "            # Calculate rotations for all joints\n",
    "            current_rotations = {}\n",
    "            \n",
    "            for joint_name, next_joint_name in joint_connections.items():\n",
    "                if joint_name in joint_positions:\n",
    "                    if next_joint_name and next_joint_name in joint_positions:\n",
    "                        # Calculate rotation based on the direction to the next joint\n",
    "                        rotation = calculate_joint_rotation(\n",
    "                            joint_positions[joint_name],\n",
    "                            joint_positions[next_joint_name]\n",
    "                        )\n",
    "                        current_rotations[joint_name] = rotation\n",
    "                    else:\n",
    "                        # For end joints, use default rotation or propagate from parent\n",
    "                        current_rotations[joint_name] = [0, 0, 0]\n",
    "                else:\n",
    "                    # If joint is not detected, use default rotation\n",
    "                    current_rotations[joint_name] = [0, 0, 0]\n",
    "            \n",
    "            # Apply simple temporal smoothing (helps with jitter)\n",
    "            smoothing_factor = 0.5  # Lower = less smoothing\n",
    "            smoothed_rotations = {}\n",
    "            \n",
    "            for joint_name, rotation in current_rotations.items():\n",
    "                if joint_name in prev_rotations:\n",
    "                    smoothed_rotations[joint_name] = [\n",
    "                        prev_rotations[joint_name][0] * smoothing_factor + rotation[0] * (1 - smoothing_factor),\n",
    "                        prev_rotations[joint_name][1] * smoothing_factor + rotation[1] * (1 - smoothing_factor),\n",
    "                        prev_rotations[joint_name][2] * smoothing_factor + rotation[2] * (1 - smoothing_factor)\n",
    "                    ]\n",
    "                else:\n",
    "                    smoothed_rotations[joint_name] = rotation\n",
    "            \n",
    "            prev_rotations = smoothed_rotations\n",
    "            \n",
    "            # Add rotations to frame data in correct hierarchical order\n",
    "            def add_rotations_recursively(joint):\n",
    "                if joint.name in smoothed_rotations:\n",
    "                    frame_data.extend(smoothed_rotations[joint.name])\n",
    "                else:\n",
    "                    frame_data.extend([0, 0, 0])  # Default rotation\n",
    "                \n",
    "                for child in joint.children:\n",
    "                    if not child.is_end_site:\n",
    "                        add_rotations_recursively(child)\n",
    "            \n",
    "            # Start with root\n",
    "            add_rotations_recursively(root_joint)\n",
    "            \n",
    "            # Add frame to BVH\n",
    "            bvh_writer.add_frame(frame_data)\n",
    "            \n",
    "            if processed_count % 10 == 0:\n",
    "                print(f\"Processed {processed_count} frames...\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Write BVH file\n",
    "    bvh_writer.write_to_file(output_path)\n",
    "    print(f\"BVH file created: {output_path}\")\n",
    "    print(f\"Total frames processed: {processed_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b72aa0b-fc13-4330-b897-e85a63e0233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: dance5.mp4\n",
      "Target FPS: 30, Frame time: 0.03333333333333333\n",
      "BVH file created: dance5.bvh\n",
      "Total frames processed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740532616.427119   36185 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1740532616.428166   36336 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1740532616.517583   36322 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740532616.625148   36331 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser(description=\"Convert video to BVH motion capture file\")\n",
    "# parser.add_argument(\"video_path\", help=\"Path to input video file\")\n",
    "# parser.add_argument(\"--output\", help=\"Path to output BVH file\")\n",
    "# parser.add_argument(\"--fps\", type=int, default=30, help=\"Target frames per second for BVH file\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# video_path = args.video_path\n",
    "# output_path = args.output\n",
    "\n",
    "# if not output_path:\n",
    "#     # Create output path if not specified\n",
    "#     video_name = Path(video_path).stem\n",
    "#     output_path = f\"{video_name}.bvh\"\n",
    "filename = \"dance5\"\n",
    "process_video(f\"{filename}.mp4\", f\"{filename}.bvh\", fps_target=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c8dbd7-4e60-4f0c-93b5-238f7b4cdc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
